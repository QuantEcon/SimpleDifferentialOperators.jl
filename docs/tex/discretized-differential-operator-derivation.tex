% !TEX program = pdflatex

\documentclass[11pt]{article}
\usepackage{amsmath,amsfonts,amsthm,amssymb,geometry,dsfont}
\usepackage[usenames,dvipsnames,svgnamesable]{xcolor}
\usepackage[capitalise,noabbrev]{cleveref} %
\usepackage{natbib,url}
\crefname{equation}{}{} %
\crefname{assumption}{Assumption}{Assumptions}
\crefname{property}{Property}{Properties}
\geometry{left=1in,right=1in,top=0.6in,bottom=1in}
\newcommand{\set}[1]{\ensuremath{\left\{{#1}\right\}}}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\diff}{\ensuremath{\mathrm{diff}}}
\newcommand{\band}{\ensuremath{\mathrm{band}}}
\newcommand{\toep}{\ensuremath{\mathrm{toep}}}
\newcommand{\tridiag}{\ensuremath{\mathrm{tridiag}}}
\newcommand{\diag}{\ensuremath{\mathrm{diag}}}
\newcommand{\D}[1][]{\ensuremath{\partial_{#1}}}
\newcommand{\indicator}[1]{\ensuremath{\mathds{1}\left\{{#1}\right\}}}
\newcommand{\condexpec}[3][]{\ensuremath{\mathbb{E}_{#1}\left[{#2} \; \middle| \; {#3} \right]}}
\newcommand{\expec}[2][]{\ensuremath{\mathbb{E}_{{#1}}\left[ {#2} \right]}}
\geometry{left=1in,right=1in,top=0.6in,bottom=1in}
\newenvironment{psmallmatrix}
{\left(\begin{smallmatrix}}
	{\end{smallmatrix}\right)}

\theoremstyle{definition}
\newtheorem{example}{Examples}[section]

\bibliographystyle{ecta}
\begin{document}
\title{Derivations and Applications for \url{SimpleDifferentialOperators.jl}}
\author{Chiyoung Ahn and Jesse Perla}
\maketitle

\section{Overview}
This package is intended to be a stop-gap while more complete and higher-performance solutions are implemented (in particular, the evolution of \url{https://github.com/JuliaDiffEq/DiffEqOperators.jl/}).  In the meantime, the package hopefully provides a solution for discretizing operators and solving ODEs/PDEs.

The focus is on discretizing linear (and, with some careful checks, affine) operators.  In the case of models where the process is non-linear, it is most appropriate for algorithms that iteratively solve linear ODEs/PDEs.  Some notation used throughout the document
\begin{itemize}
	\item Let $x \in R$ be the general ``spatial'' state  variable

	\item Derivatives are denoted by the operator $\D[x]$ and univariate derivatives such as $\D[x]\tilde{v}(x) \equiv \tilde{v}'(x)$
	\item Use the vertical bar to denote operator evaluation at a particular point.  That is if $\tilde{B} \equiv \partial_x\vert_{x = x_0}$ then $\tilde{B} \tilde{v}(x) = \partial_x \tilde{v}(x_0)$, and if $\tilde{B} \equiv 1 \vert_{x = x_0}$ then $\tilde{B} \tilde{v}(x) = \tilde{v}(x_0)$.  For the notation, the $1$ is simply the identity operator on the function instead of applying a derivative (i.e. $\tilde{B} \equiv 1 \vert_{x = x_0}$ then $\tilde{B} \tilde{v}(\cdot) = 1 \times \tilde{v}(x_0) $)
	\item Let $W_t$ be the Wiener process with the integral defined by the Ito interpretation

\end{itemize}


\subsection{Linear Differential Equations}


\paragraph{ODEs (e.g. Steady State)}
To understand the class of models that this can support, first look at the sort of ODE that comes out of solving a stationary model.  The general pattern is a linear differential operator $\tilde{L}$, a boundary condition operator $\tilde{B}$, the function of interest $\tilde{v}(x)$, and the affine terms $\tilde{f}(\cdot)$ and $b$. The general problem to solve is to find the $\tilde{v}(x)$ such that
\begin{align}
	0 &= \tilde{L} \tilde{v}(x) - \tilde{f}(x)\label{eq:A-u-DE}\\
	0 &= \tilde{B} \tilde{v}(x) - b\label{eq:B-u-DE}
\end{align}

\paragraph{Motivating Example}
As a simple example, let
\begin{itemize}
	\item $x \in [x_{\min},x_{\max}]$ be a state variable on a domain following the SDE
	\begin{equation} 
		d x_t = \mu d t + \sigma d W_t
	\end{equation}
	where the variable $x_t$ is reflected at $x_{\min}$ and $x_{\max}$
	\item The payoffs for state $x$ are a function $\tilde{f}(x)$ defined on the domain 
	\item $\tilde{v}(x)$ as the value of the the stream of payoffs discounted at rate $r > 0$
\end{itemize}
Then, through standard arguments, the stationary Bellman equation along with boundary conditions is
\begin{align}
	r \tilde{v}(x) &= \tilde{f}(x) + \mu \D[x] \tilde{v}(x) + \frac{\sigma^2}{2} \D[xx]\tilde{v}(x)\\
	\D[x]\tilde{v}(x_{\min}) &= 0\\
	\D[x] \tilde{v}(x_{\max}) &= 0
\end{align}

\noindent Mapping to the notation of \cref{eq:A-u-DE,eq:B-u-DE}
\begin{align}
	\tilde{L} &\equiv r - \mu \D[x] - \frac{\sigma^2}{2}\D[xx]\\
	\tilde{B} &\equiv \begin{bmatrix}
	\partial_x\vert_{x = x_{\min}}\\
	\partial_x\vert_{x = x_{\max}}
\end{bmatrix}\\
b &\equiv \begin{bmatrix} 0\\ 0 \end{bmatrix}
\end{align}
This package will allow you to define the $\tilde{L},\tilde{B},$ and $b$ to solve for a discretization of the $\tilde{v}(x)$ function.


\paragraph{PDEs (i.e. Time-Varying)}
The motivating example above has no time-variation in any of the parameters, payoffs, or boundary conditions. Consider that the operators, payoffs, and boundary conditions could change over time -- which we denote with a $t$ subscript. As a variation on \cref{eq:A-u-DE,eq:B-u-DE}
\begin{align}
	\D[t] \tilde{v}(t,x) &= \tilde{L}(t) \tilde{v}(t, x) - \tilde{f}(t, x)\label{eq:A-u-DE-t}\\
	0 &= \tilde{B}(t) \tilde{v}(t, x) - b(t)\label{eq:B-u-DE-t}
\end{align}
Subject to an initial condition, $\tilde{v}(0,x)$ given or potentially a boundary value, $\tilde{v}(T,x)$ for some $T$.

This is a linear PDE where the operators, boundary conditions, and payoffs all may change over time.


\paragraph{Motivating Example for Dynamics}
Going back to the motivating example, consider an extension where   We will make the following assumptions
\begin{itemize}
	\item The discount rate, drift, and payoffs could be time varying. i.e. $r(t), \mu(t)$ and $\tilde{f}(t,x)$.
	\item After some $T$ the system is stationary because $r(t) = r(T), \mu(t) = \mu(T)$ and $\tilde{f}(t,x) = \tilde{f}(T,x)$ for all $t \geq T$
\end{itemize}

\noindent Through standard arguments, the Bellman equation is
\begin{align}
	r \tilde{v}(t, x) &= \tilde{f}(t, x) + \mu(t) \D[x] \tilde{v}(t,x) + \frac{\sigma^2}{2} \D[xx]\tilde{v}(t,x) + \D[t] \tilde{v}(t, x)\\
	\D[x]\tilde{v}(t, x_{\min}) &= 0\\
	\D[x] \tilde{v}(t, x_{\max}) &= 0
\end{align}

\noindent Mapping to the notation of the PDE in \cref{eq:A-u-DE-t,eq:B-u-DE-t}
\begin{align}
	\tilde{L}(t) &\equiv r(t) - \mu(t) \D[x] - \frac{\sigma^2}{2}\D[xx]\\
	\tilde{B} &\equiv \begin{bmatrix}
	\partial_x\vert_{x = x_{\min}}\\
	\partial_x\vert_{x = x_{\max}}
\end{bmatrix}\\
b &\equiv \begin{bmatrix} 0\\ 0 \end{bmatrix}
\end{align}

In order to find the steady state, we can solve the stationary equation with $\D[t] \tilde{v}(T, x) = 0$ (i.e. with $\tilde{L}(T)$ fixed to find $\tilde{v}(T,x)$) and then use the  $\tilde{v}(T,x)$ as a boundary value to solve for the $\tilde{v}(t,x)$ by solving the PDE in


\paragraph{Boundary Conditions}
The package supports some key boundary conditions used for stochastic processes and ODE/PDEs.

As will become clear in the discretization, whether the boundary condition is homogenous or not (i.e. $b = 0$ or $b>0$) is important for the numerical methods.  If the boundary conditions are inhomogeneous, then the setup is affine.  To detail a few of the one-dimensional versions of the supported boundary conditions

\begin{itemize}
	\item Reflecting Barriers (i.e. homogeneous Neumann Boundary Conditions)
	\begin{align}
		\D[x]\tilde{v}({x_{\min}} ) &= 0\label{eq:reflecting-BC1}\\
		\D[x]\tilde{v}({x_{\max}}) &= 0\label{eq:reflecting-BC2}
	\end{align}
	or in operator form
	\begin{align}
		\tilde{B} &\equiv \begin{bmatrix}
		\partial_x\vert_{x = x_{\min}}\\
		\partial_x\vert_{x = x_{\max}}
		\end{bmatrix}\\
		b &\equiv \begin{bmatrix} 0\\ 0 \end{bmatrix}
	\end{align}
	\item Mixed boundary conditions (i.e homogeneous Robin Boundary Conditions):
	\begin{align}
	\underline{\xi} \tilde{v}({x_{\min}}) + \D[x]\tilde{v}({x_{\min}} ) &= 0\label{eq:mixed-BC1}\\
	\overline{\xi} \tilde{v}({x_{\max}}) + \D[x]\tilde{v}({x_{\max}}) &= 0\label{eq:mixed-BC2}
	\end{align}
	Note that when $\underline{\xi} = \overline{\xi} = 0$, this nests the reflecting barriers.  In operator form,
	\begin{align}
		\tilde{B} &\equiv \begin{bmatrix}
		\partial_x\vert_{x = x_{\min}} + \underline{\xi}\,1 \vert_{x = x_{\min}}\\
		\partial_x\vert_{x = x_{\max}} + \bar{\xi}\,1 \vert_{x = x_{\max}}
		\end{bmatrix}\\
		b &\equiv \begin{bmatrix} 0\\ 0 \end{bmatrix}
	\end{align}
	\item Absorbing Barriers (i.e. homogenous or inhomogeneous Dirichlet Boundary Conditions)
	\begin{align}
		\tilde{v}({x_{\min}} ) &= b_1\label{eq:absorbing-BC1}\\
		\tilde{v}({x_{\max}}) &= b_2\label{eq:absorbing-BC2}
	\end{align}
	In the case of $b_1 = b_2 = 0$, this is homogeneous. In operator form,
	\begin{align}
		\tilde{B} &\equiv \begin{bmatrix}
		1 \vert_{x = x_{\min}}\\
		1 \vert_{x = x_{\max}}
		\end{bmatrix}\\
		b &\equiv \begin{bmatrix} b_1\\ b_2 \end{bmatrix}
	\end{align}
\end{itemize}
Of course, many models would have different boundary conditions on different sides of the domain, which entails mixing and matching rows in the $B$ and $b$ matrices.

%This package will allow you to define the $\tilde{L},\tilde{B},$ and $b$ to solve for a discretization of the $\tilde{v}(x)$ function.

\section{Discretization}
\subsection{Notation}
This section defines the grids and other notation for the discretization.
\begin{itemize}
	\item Define an irregular grid $\set{x_i}_{i=0}^{M+1}$ with \textbf{boundary nodes}, $x_0 = {x_{\min}}$ and $x_{M+1} = {x_{\max}}$. Denote the \textbf{extended grid} as $\overline{x} \equiv \set{x_i}_{i=0}^{M+1}$ and the \textbf{interior grid}, a collection of nodes excluding the boundary nodes, as $x \equiv \set{x_i}_{i=1}^{M} $.
	\item Recall that the continuous functions, prior to discretization, are denoted like $\tilde{u}(x)$.  The discretization of $\tilde{u}(x)$ on the interior $x\in \R^M$ is denoted $u \equiv \set{\tilde{u}(x_i)}_{i=1}^M\in \R^M$ and the discretization of $\tilde{u}(x)$ on $\bar{x} \in \R^{M+2}$ is $\bar{u} \equiv \set{\tilde{u}(x_i)}_{i=0}^{M+1} \in \R^{\bar{M+2}}$.
	\item When we discretize a particular operator, e.g. $\tilde{L}$, we will drop the tilde to become $L$.  The typical size of this, before applying boundary conditions, is $L \in \R^{M \times (M+2)}$.
	\item Denote the backward and forward distance between the grid points as
	\begin{align}
	\Delta_{i,-} &\equiv x_i - x_{i-1},\, \text{for } i = 1,\ldots, M+1\\
	\Delta_{i,+} &\equiv x_{i+1} - x_i,\, \text{for } i = 0,\ldots, M
	\end{align}
	\item Define the vector of backwards and forwards first differences, padding with $\Delta_{0,-} = \Delta_{M+1,+} = 0$, as
	\begin{align}
	\Delta_{-} &\equiv \begin{bmatrix} 0 \\
	\text{diff}(z)
	\end{bmatrix}\in\R^{M+2}\label{eq:Delta-minus}\\
	\Delta_{+} &\equiv \begin{bmatrix} \text{diff}(z)\\
	0
	\end{bmatrix}\in\R^{M+2}
	\end{align}
	\item Some special matrices to help in the composition notation:
	\begin{itemize}
		\item $\mathbf{I}_N$ is the $N\times N$ identity matrix.  Always drop the subscript when the dimensions are unambiguous, as it would be the same in the code
		\item $\mathbf{0}_N$ is the column vector of $N$ $0$s, and $\mathbf{0}_N^{\top}$ a row vector
		\item $\mathbf{0}_{N\times M}$ is the $N\times M$ matrix of $0$s
		\item See \cref{sec:special-matrices} for the definitions of $\toep(\cdot), \band^{n,m}_{l,u}(\cdot)$ and $\tridiag(\cdot)$ matrices
	\end{itemize}
\end{itemize}

In order to discretize these operators with finite-differences, we need to choose a stencil.  Denote the discretization
\begin{itemize}
	\item For the first-derivative operator $\tilde{L}_1 \equiv \D[x]$, denote the stencils for discretizing with backwards and forward first-differences respectively as $L_{1-}\in \R^{M\times(M+2)}$ and $L_{1+}\in \R^{M\times(M+2)}$.\footnote{Note that the stencil for both of these only really needs to be defined on $M \times (M+1)$ but we will pad a column with $0$s to make composition easier. In the current form, the package composes operators as sparse matrices.  Depending on the circumstances, this code will execute slower than a hand-tweaked model creating composed operators directly.  In many cases, this wouldn't be a problem, but in some algorithms where operators need to be redefined frequently in tight loops, it might be.  In those cases, use the output of this package for test-suites on hand-built discretizations.}
	\item For the second-derivative operator $\tilde{L}_2 \equiv \D[x x]$, always use central differences and denote the discretized operator as $L_2 \in \R^{M\times(M+2)}$
\end{itemize}
For first-derivatives, the choice of $L_{1-}$ vs. $L_{1+}$ or a combination of them, will use upwind finite differences.




\section{Discretizing Operators with a Regular Grid}
In this section, we study discretization schemes under regular grids, i.e., grids such that $x_{i+1} - x_i = \Delta$ for all $i = 0,...,M$ for some fixed $\Delta > 0$.

Throughout, take a function of interest $\tilde{v}(x)$ defined on the grid, and define $\bar{v} \equiv \set{\tilde{v}(x_i)}_{i=0}^{M+1}$ and $v \equiv \set{\tilde{v}(x_i)}_{i=1}^{M}$.

\subsection{Discretized Operators}
In this section we derive the stencils for operators of various orders.

\paragraph{First Derivative Operators}
To discretize the $\tilde{L}_1$ operator, we can use a backward difference approximation
 \begin{align}
\tilde{L}_1 \tilde{v}(x_i) &\equiv \D[x] \tilde{v}(x_i) \approx \frac{\bar{v}_i - \bar{v}_{i-1}}{\Delta},\, \text{ for } i = 1,\ldots, M\label{eq:first-order-bd}\\
\intertext{And with forward differences}
\tilde{L}_1 \tilde{v}(x_i) &\equiv \D[x] \tilde{v}(x_i) \approx \frac{\bar{v}_{i+1} - \bar{v}_i}{\Delta},\, \text{ for } i = 1,\ldots, M\label{eq:first-order-fd}
\end{align}

In order to calculate the derivatives for all $i = 1, \ldots, M$ (i.e. in the interior) we can stack these up and apply to the extension $\bar{v}$.
\begin{align}
\set{\D[x]\tilde{v}(x_i)}_{i=1}^M &\approx L_{1-} \cdot \bar{v}
\intertext{or,}
\set{\D[x]\tilde{v}(x_i)}_{i=1}^M &\approx L_{1+} \cdot \bar{v}
\intertext{Where we define $L_{1-}$ from applying \cref{eq:first-order-bd} to the $\bar{v}$ vector for all $i = 1,\ldots, M$ }
L_{1-} &\equiv \frac{1}{\Delta}\begin{bmatrix}
-1 &1 &0&\dots&0&0&0&0\\
0&-1&1&\ddots&0&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots&\vdots\\
0&0&0&\dots&-1&1&0&0\\
0&0&0&\cdots&0&-1&1&0
\end{bmatrix}_{M\times (M+2)}\label{eq:L-1-m-extended-regular} \\
&= \frac{1}{\Delta}\band^{M,M+2}_{0,1}(-\mathbf{1}_M, \mathbf{1}_M)
\intertext{And similarly define $L_{1+}$ from applying \cref{eq:first-order-fd} to the $\bar{v}$ vector for all $i = 1,\ldots, M$ }
L_{1+} &\equiv \frac{1}{\Delta}\begin{bmatrix}
0&-1&1&0&\dots&0&0&0\\
0&0&-1&1&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&0&\dots&-1&1&0\\
0&0&0&0&\cdots&0&-1&1
\end{bmatrix}_{M\times( M+2)}\label{eq:L-1-plus-extended-regular} \\
&= \frac{1}{\Delta}\band^{M,M+2}_{0,2}(\mathbf{0}_M, -\mathbf{1}_M, \mathbf{1}_M)
\end{align}
It is important to note that while these operators map the $\bar{v}$ (i.e. including the boundary points), the operator only maps to points on the interior i.e. $i = 1, \ldots, M$.



\paragraph{Second Derivative Operators}
To discretize the $\tilde{L}_2$ second order operator, we can use central differences
\begin{equation}
\tilde{L}_2 \tilde{v}(x_i) \equiv \D[x x ] \tilde{v}(x_i) \approx \dfrac{\bar{v}_{i+1} - 2 \bar{v}_{i} + \bar{v}_{i-1} }{\Delta^2},\, \text{ for } i = 1,\ldots, M\label{eq:second-order}
 \end{equation}

In order to calculate the derivatives for all $i = 1, \ldots, M$ (i.e. in the interior) we can stack these up and apply to the extension $\bar{v}$
\begin{align}
	\set{\D[x x ]\tilde{v}(x_i)}_{i=1}^M &\approx L_{2} \cdot \bar{v}
	\intertext{Where we define $L_2$ from applying \cref{eq:second-order} to the $\bar{v}$ vector for all $i = 1,\ldots, M$ }
	L_2 &\equiv \frac{1}{\Delta^2}\begin{bmatrix}
	1&-2  &1&0&\dots&0&0&0&0\\
	0&1&-2&1&\dots&0&0&0&0\\
	\vdots&\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots&\vdots\\
	0&0&0&0&\dots&1&-2&1&0\\
	0&0&0&0&\cdots&0&1&-2 &1
	\end{bmatrix}_{M\times (M+2)}\label{eq:L-2-extended-regular}\\
	&= \frac{1}{\Delta^2}\band_{0,2}^{M,M+2}(\mathbf{1}_M, -2\times\mathbf{1}_M, \mathbf{1}_M)
\end{align}

\paragraph{Identity Operators}
For simplicity in composition, also consider the discretization of the identity operator (i.e. not applying any derivatives or stencils).  For simplicity, define the identity operator as the $0$-th order operator $\tilde{L}_0 \equiv I$ so that $\tilde{L}_0 \tilde{v}(x) = \tilde{v}(x)$.

With this, the operator applied to the $\bar{v}$ vector is trivial
\begin{align}
\tilde{L}_0 \tilde{v}(x_i) &\equiv \tilde{v}(x_i) = \bar{v}_i,\, \text{ for } i = 1,\ldots, M\label{eq:zero-order}
\intertext{And stacking it up for all $i = 1, \ldots, M$,}
\set{\tilde{v}(x_i)}_{i=1}^M &\approx L_0 \cdot \bar{v}
\intertext{Where}
L_0 &\equiv \begin{bmatrix}
0 & 1 & 0 & 0 &\dots & 0 & 0 & 0 &0\\
0 & 0 & 1 & 0 &\dots & 0 & 0 & 0 &0\\
\vdots&\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots&\vdots\\
0 & 0 & 0 & 0 &\dots & 0 & 1 & 0 &0\\
0 & 0 & 0 & 0 &\dots & 0 & 0 & 1 &0
\end{bmatrix}_{M\times (M+2)}\\
&= \begin{bmatrix} \mathbf{0}_M &\mathbf{I}_M & \mathbf{0}_M  \end{bmatrix}\\
&= \band_{0,1}^{M,M+2}(\mathbf{0}_M, \mathbf{1}_M)
\end{align}
This operator trivially maps from the $\bar{v}$ to extract the interior $v$ and ignoring the boundaries $\bar{v}_0$ and $\bar{v}_{M+1}$.  Its primary role will be when composing operators rather than being used directly.

\subsection{Boundary Conditions}
While boundary conditions can be mixed and matched, for notational simplicity here, we will apply the same boundaries at each corner.  In general, boundaries are of the form
\begin{align}
\tilde{B} \tilde{v}(x) &= b\label{eq:BC-system}
\end{align}
For some operator $\tilde{B}$ (typically involving evaluation at the boundaries) and $b\in R^2$.  In the case of $b = \textbf{0}_2$, the boundary conditions are called homogenous.

\subsubsection{Mixed boundary conditions}
Recall mixed boundary conditions from \cref{eq:mixed-BC1,eq:mixed-BC2}. Note that reflecting barrier conditions are special cases with $\overline{\xi} = \underline{\xi} = 0$.  In operator form, the boundaries are

\begin{align}
\tilde{B} &\equiv \begin{bmatrix}
\partial_x\vert_{x = x_{\min}} + \underline{\xi}\,1 \vert_{x = x_{\min}}\\
\partial_x\vert_{x = x_{\max}} + \bar{\xi}\,1 \vert_{x = x_{\max}}
\end{bmatrix}\label{eq:mixed}\\
b &\equiv \begin{bmatrix} 0\\ 0 \end{bmatrix}\in \R^2
\end{align}

Using forward difference and backward differences respectively to discretize the first derivatives at the lower and upper bound of \cref{eq:mixed} gives the system \cref{eq:BC-system} as
\begin{align}
\frac{\overline{v}_1 - \overline{v}_0}{\Delta} + \underline{\xi} \overline{v}_0 &= 0\label{eq:regular-mixed-1} \\
\frac{\overline{v}_{M+1} - \overline{v}_M}{\Delta} + \overline{\xi} \overline{v}_{M+1} &= 0\label{eq:regular-mixed-2}
\end{align}

Define
\begin{align}
B &\equiv \begin{bmatrix}
-\dfrac{1}{\Delta} + \underline{\xi} & \dfrac{1}{\Delta} & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -\dfrac{1}{\Delta} & \dfrac{1}{\Delta} + \overline{\xi}\\
\end{bmatrix}_{2 \times (M+2)}\label{eq:mixed-barrier-matrix-original-regular}\\
b &= \begin{bmatrix}
0 \\
0
\end{bmatrix}
\end{align}

Then, multiplying by $\Delta$, the system has the same $b$ and \cref{eq:mixed-barrier-matrix-original-regular}  equivalent to
\begin{equation}
B = \begin{bmatrix}
-1 +  \underline{\xi} \Delta & 1 & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -1 & 1 + \overline{\xi} \Delta\\
\end{bmatrix}_{2 \times (M+2)}\label{eq:B-mixed}
\end{equation}

Depending on the direction of the drift, the locations of $\overline{\xi}$ and $\underline{\xi}$ have to be different. When the drift is drift is negative on the lower bound and is positive on the upper bound, we have

\begin{align}
\frac{\overline{v}_1 - \overline{v}_0}{\Delta} + \underline{\xi} \overline{v}_1 &= 0 \label{eq:mixed-BC1-negative}  \\
\frac{\overline{v}_{M+1} - \overline{v}_M}{\Delta} + \overline{\xi} \overline{v}_{M} &= 0 \label{eq:mixed-BC2-positive}
\end{align}

Hence, letting $\circ_1, \circ_M \in \{-, +\}$ denote the drift directions on the lower and upper boundaries respectively, there are four corresponding boundary condition matrices $B^{\circ_1 \circ_M}$ as follows:
 
\begin{align}
B^{--} &\equiv 
\begin{bmatrix}
-\dfrac{1}{\Delta} & \dfrac{1}{\Delta}  + \underline{\xi} & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -\dfrac{1}{\Delta} & \dfrac{1}{\Delta} + \overline{\xi}\\
\end{bmatrix}_{2 \times (M+2)} \\
B^{+-} &\equiv 
\begin{bmatrix}
-\dfrac{1}{\Delta} + \underline{\xi} & \dfrac{1}{\Delta} & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -\dfrac{1}{\Delta} & \dfrac{1}{\Delta} + \overline{\xi}\\
\end{bmatrix}_{2 \times (M+2)} \\
B^{-+} &\equiv 
\begin{bmatrix}
-\dfrac{1}{\Delta}  & \dfrac{1}{\Delta} + \underline{\xi} & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -\dfrac{1}{\Delta}+ \overline{\xi} & \dfrac{1}{\Delta}\\
\end{bmatrix}_{2 \times (M+2)} \\
B^{++} &\equiv 
\begin{bmatrix}
-\dfrac{1}{\Delta} + \underline{\xi} & \dfrac{1}{\Delta} & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -\dfrac{1}{\Delta}+ \overline{\xi} & \dfrac{1}{\Delta} \\
\end{bmatrix}_{2 \times (M+2)}
\end{align}

Multiplying all rows by $\Delta$, the resulting system has the same $b$ and the following $B^{--}, B^{+-}, B^{-+}, B^{++}$:
 
\begin{align}
B^{--} &\equiv 
\begin{bmatrix}
-1 & 1  + \underline{\xi}\Delta & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -1 & 1 + \overline{\xi}\Delta\\
\end{bmatrix}_{2 \times (M+2)} \\
B^{+-} &\equiv 
\begin{bmatrix}
-1 + \underline{\xi}\Delta & 1 & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -1 & 1 + \overline{\xi}\Delta\\
\end{bmatrix}_{2 \times (M+2)} \\
B^{-+} &\equiv 
\begin{bmatrix}
-1  & 1 + \underline{\xi}\Delta & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -1+ \overline{\xi}\Delta & 1\\
\end{bmatrix}_{2 \times (M+2)} \\
B^{++} &\equiv 
\begin{bmatrix}
-1 + \underline{\xi}\Delta & 1 & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -1+ \overline{\xi}\Delta & 1 \\
\end{bmatrix}_{2 \times (M+2)}
\end{align}



\subsubsection{Reflecting Barriers}
Since a reflecting barrier (i.e. a Neumann boundary condition) is a special case of the mixed boundary condition when  $\underline{\xi} = \bar{\xi} = 0$, the $B$ matrix for a reflecting barrier follows \cref{eq:B-mixed}
\begin{equation}
	B = \begin{bmatrix}
	-1& 1 & 0 & \dots & 0 & 0 & 0 \\
	0 & 0 & 0 & \dots & 0 & -1 & 1\\
	\end{bmatrix}_{2 \times (M+2)}
	\end{equation}
with the same 
\begin{equation}
	b = \begin{bmatrix}	
			0 \\
		 	0
		 	\end{bmatrix}
\end{equation}

Note that this does not depend on the direction of the drift as $B^{--} = B^{+-} = B^{-+} = B^{++}$ when $\overline{\xi} = \underline{\xi} = 0$.

	\subsubsection{Absorbing Barriers}

With the homogenous or inhomogeneous Dirichlet Boundary Conditions in \cref{eq:absorbing-BC1,eq:absorbing-BC2}, in operator form,
\begin{align}
	\tilde{B} &\equiv \begin{bmatrix}
	1 \vert_{x = x_{\min}}\\
	1 \vert_{x = x_{\max}}
	\end{bmatrix}
\end{align}

Implementing this for the system in \cref{eq:BC-system} gives,

\begin{align}
B &= \begin{bmatrix}
1 & 0 & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & 0 & 1\\
\end{bmatrix}_{2 \times (M+2)}\label{eq:absorbing-barrier-matrix-regular}\\
b &= \begin{bmatrix}
b_1 \\
b_2
\end{bmatrix}
\end{align}

\subsection{Solving ODEs and PDEs}
Going back to the motivation, a typical scenario might be to solve the stationary problem \cref{eq:A-u-DE,eq:B-u-DE}
\begin{align}
	\tilde{L} \tilde{v}(x) &= \tilde{f}(x)\\
	\tilde{B} \tilde{v}(x) &= b
\end{align}

Boundary conditions can be applied manually by using operators on extended grids, $\overline{x}$, to find solutions on extended grids.  First, apply $\tilde{f}(x)$ to the interior, $x$ to get  $f$ then solve the system of $M+2$ equations

\begin{align}
\begin{bmatrix}
L \\
B
\end{bmatrix}
\overline{v} =
\begin{bmatrix}
f \\
b
\end{bmatrix}\label{eq:reflecting-barrier-extended-system}
\end{align}

To get the $v\in \R^M$ in the interior, we can just take the interior of the resulting $\bar{v}$
\begin{align}
	\overline{v} = \begin{bmatrix}
	\tilde{v}(x_0) \\
	v \\
	\tilde{v}(x_{M+1})
	\end{bmatrix}
\end{align}
which also gives the solution for $v$.

\paragraph{Discretizing PDEs to DAEs}
The PDEs that come out of these operators are more of an issue.  A common setup becomes (with $\tilde{L}(t)$ and $\tilde{B}(t)$ time varying operators)

\begin{align}
	\D[t] \tilde{v}(t,x) &= \tilde{L}(t) \tilde{v}(t,x) - \tilde{f}(t,x)  \\
	0 &= \tilde{B}(t) \tilde{v}(t,x) - b(t)
\end{align}

Now, if you were able to discretize this to find a time varying $\bar{v}(t)$, you could potentially discretize the setup as
\begin{align}
	\D[t] \bar{v}(t) &= L(t) \bar{v}(t) - f(t)\\
	0 &= B(t) \bar{v}(t) - b(t)
\end{align}
i.e. a system of $M+2$ differential-algebraic equations given time varying matrices $L(t), B(t)$ and vectors $f(t) \in R^M$ and $b \in \R^2$.


\subsection{Applying Boundary Conditions to Operators}

An alternative approach to solving the systems of $M+2$ equations or DAEs above is to apply the boundary conditions directly to the $L$ operators and solve for the $v$ or $v(t)$ directly.  In effect, the methods are identical to applying Gaussian elimination twice to the above systems.

\subsubsection{Mixed Boundary Conditions}

Adding the first row of $L_{1-}$ by the first row of $B$ in \eqref{eq:B-mixed} multiplied by $(-1 + \underline{\xi} \Delta )^{-1}\Delta^{-1}$ gives, with the corresponding row operation matrix $R$,

\begin{equation}
R {L}_{1-} = \dfrac{1}{\Delta} \begin{bmatrix}
0&1 + (-1 + \underline{\xi}\Delta )^{-1}&0&0&\dots&0&0&0&0\\
0&-1&1&0&\ddots&0&0&0&0\\
\vdots&\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots&\vdots\\
0&0&0&0&\dots&-1&1&0&0\\
0&0&0&0&\cdots&0&-1&1&0
\end{bmatrix}_{M\times (M+2)}
\end{equation}
note that there is no zero element in the first and last column for nodes on boundaries. Hence, solving the corresponding extended system,
\begin{align}
\begin{bmatrix}
{L}\\
B
\end{bmatrix} 
\overline{v} 
=
\begin{bmatrix}
f \\ b
\end{bmatrix}
\end{align}
is identical as solving the following system
\begin{align}
R
\begin{bmatrix}
{L}\\
B
\end{bmatrix} 
\overline{v} 
&=
R
\begin{bmatrix}
f \\ b
\end{bmatrix} \\
&= \begin{bmatrix}
f \\ b
\end{bmatrix}
\end{align}
as $b$ is a zero vector so that the row operations $R$ do not change anything on the RHS. Furthermore, limited to the interior, solving $v$ in the system above is identical as solving the following system with an operator $L^B$ on interior nodes:
\begin{equation}\label{eq:system-on-interior}
L^B v = f
\end{equation}
where we have ${L} = {L}_{1-}$ and $L^B = L_{1-}^B$ with
\begin{equation}
L_{1-}^B \equiv \frac{1}{\Delta}\begin{bmatrix}
1 + (-1 + \underline{\xi} \Delta)^{-1} &0&0&\dots&0&0&0\\
-1&1&0&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&-1&1&0\\
0&0&0&\cdots&0&-1&1
\end{bmatrix}_{M\times M} \label{eq:L-1-regular}
\end{equation}
instead of solving the full system with boundary conditions. Similarly, subtracting the first row of $L_{1+}$ by the second row of $B$ in \eqref{eq:B-mixed} multiplied by $(1 + \overline{\xi} \Delta )^{-1} \Delta^{-1}$ gives the following differential operator with the boundary condition $B$ applied:
\begin{align}
L_{1+}^B &\equiv \frac{1}{\Delta}\begin{bmatrix}
-1&1&0&\dots&0&0&0\\
0&-1&1&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&0&-1&1\\
0&0&0&\cdots&0&0&-1+(1+\overline{\xi} \Delta)^{-1}
\end{bmatrix}_{M\times M}\label{eq:L-1-plus-regular}
\end{align}
And by substracting the first row of $L_2$ by the first row of $B$ multiplied by $(-1 + \underline{\xi} \Delta )^{-1} \Delta^{-2}$ and the last row of $L_2$ by the second row of $B$ multiplied by $(1 + \overline{\xi} \Delta)^{-1} \Delta^{-2}$, we have the following differential operator with the boundary condition $B$ applied for $L_2$:
\begin{align}
L_2^B &\equiv \frac{1}{\Delta^2}\begin{bmatrix}
-2 - (-1 + \underline{\xi}\Delta)^{-1} &1&0&\dots&0&0&0\\
1&-2&1&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&1&-2&1\\
0&0&0&\cdots&0&1&-2 +(1+ \overline{\xi}\Delta)^{-1}
\end{bmatrix}_{M\times M}\label{eq:L-2-regular}
\end{align}

which can be defined in more compact forms:
\begin{align}
L_{1-}^B &\equiv \Delta^{-1}
\left[ 
\text{tridiag}(-\mathbf{1}_{M-1}, 
\mathbf{1}_{M}, \mathbf{0}_{M-1} ) + \diag \left( \begin{bmatrix}
(-1+\underline{\xi} \Delta)^{-1} &
\mathbf{0}_{M-1}^T 
\end{bmatrix}^T
\right)
\right]
\end{align}
\begin{align}
L_{1+}^B &\equiv 
\Delta^{-1}
\left[ 
\text{tridiag}(-\mathbf{0}_{M-1}, 
\mathbf{-1}_{M}, \mathbf{1}_{M-1} ) + \diag \left( \begin{bmatrix}
\mathbf{0}_{M-1}^T &
(1+\overline{\xi} \Delta)^{-1}
\end{bmatrix}^T
\right)
\right]
\end{align}
\begin{align}
L_2^B \equiv  \Delta^{-2} 
\Big[ 
&\text{tridiag}(
\mathbf{1}_{M-1},
-2 \times \mathbf{1}_M,
\mathbf{1}_{M-1} )
+ \\
&\diag \left( \begin{bmatrix}
-(-1+\underline{\xi} \Delta)^{-1}&
\mathbf{0}_{M-2}^T &
(1+\overline{\xi} \Delta)^{-1}
\end{bmatrix}^T \right)
\Big]
\end{align}

\paragraph{Applying drift directions on boundary conditions}
Adding the first row of $B^{--}$ or $B^{-+}$ multiplied by $\Delta^{-1}$ on the first row of $L_{1-}$ and extracting the interior yields

\begin{equation}
L_{1-}^{B-} \equiv \frac{1}{\Delta}\begin{bmatrix}
-\underline{\xi} \Delta &0&0&\dots&0&0&0\\
-1&1&0&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&-1&1&0\\
0&0&0&\cdots&0&-1&1
\end{bmatrix}_{M\times M} \label{eq:L-1-regular-left}
\end{equation}

Likewise,
Adding the first row of $B^{-+}$ or $B^{++}$ multiplied by $\Delta^{-1}$ on the first row of $L_{1+}$ and extracting the interior yields

\begin{equation}
L_{1+}^{B+} \equiv \frac{1}{\Delta}\begin{bmatrix}
-1 &1&0&\dots&0&0&0\\
0&-1&1&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&0&-1&1\\
0&0&0&\cdots&0&0&-\overline{\xi} \Delta
\end{bmatrix}_{M\times M} \label{eq:L-1p-regular-right}
\end{equation}

For $L_2$, directions on both boundaries affect the interior. Here we study the two upper and lower boundaries separately. For the lower boundary, suppose first that the drift is positive. Substracting the first row of $L_2$ by the first row of $B^{+-}$ or $B^{++}$ multiplied by $(-1 + \underline{\xi} \Delta )^{-1} \Delta^{-2}$ and extracting the interior and first row gives
\begin{align}
\frac{1}{\Delta^2}\begin{bmatrix}
-2 - (-1 + \underline{\xi}\Delta)^{-1} &1&0&\dots&0&0&0
\end{bmatrix}_{1\times M}
\end{align}

Suppose that we have a negative drift at the lower boundary. Adding the first row of $L_2$ by the first row of $B^{--}$ or $B^{-+}$ multiplied by $\Delta^{-2}$ and extracting the interior and first row gives
\begin{align}
\frac{1}{\Delta^2}\begin{bmatrix}
-1 + \underline{\xi}\Delta &1&0&\dots&0&0&0
\end{bmatrix}_{1\times M}
\end{align}

Now consider the upper boundary. Suppose first that the drift is negative. Substracting the last row of $L_2$ by the second row of $B^{--}$ or $B^{+-}$ multiplied by $(1 + \overline{\xi} \Delta)^{-1} \Delta^{-2}$ and extracting the interior and last row gives 
\begin{align}
\frac{1}{\Delta^2}\begin{bmatrix}
0&0&0&\cdots&0&1&-2 +(1+ \overline{\xi}\Delta)^{-1}
\end{bmatrix}_{1\times M}
\end{align}

Suppose that we have a positive drift at the upper boundary. Subtracting the second row of $L_2$ by the first row of $B^{-+}$ or $B^{++}$ multiplied by $\Delta^{-2}$ and extracting the interior and last row gives
\begin{align}
\frac{1}{\Delta^2}\begin{bmatrix}
0&0&0&\cdots&0&1&-1 - \overline{\xi}\Delta
\end{bmatrix}_{1\times M}
\end{align}

This provides the complete combination of all possible drift directions on both boundaries for $L_2$. For instance, $L_2^{B-+}$ is defined as
\begin{align}
L_2^{B-+} &\equiv \frac{1}{\Delta^2}\begin{bmatrix}
-1 + \underline{\xi}\Delta &1&0&\dots&0&0&0\\
1&-2&1&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&1&-2&1\\
0&0&0&\cdots&0&1&-1 - \overline{\xi}\Delta
\end{bmatrix}_{M\times M}
\end{align}

Using banded matrices, these operators can be definied in the following compact forms:

\begin{align}
L_{1-}^{B-} &\equiv \Delta^{-1}
\left[ 
\text{tridiag}(-\mathbf{1}_{M-1}, 
\mathbf{1}_{M}, \mathbf{0}_{M-1} ) + \diag \left( \begin{bmatrix}
1 - \underline{\xi} \Delta &
\mathbf{0}_{M-1}^T 
\end{bmatrix}^T
\right)
\right] \\
L_{1-}^{B+} &\equiv \Delta^{-1}
\left[ 
\text{tridiag}(-\mathbf{1}_{M-1}, 
\mathbf{1}_{M}, \mathbf{0}_{M-1} ) + \diag \left( \begin{bmatrix}
(-1+\underline{\xi} \Delta)^{-1} &
\mathbf{0}_{M-1}^T 
\end{bmatrix}^T
\right)
\right] 
\end{align}
\begin{align}
L_{1+}^{B-} &\equiv 
\Delta^{-1}
\left[ 
\text{tridiag}(-\mathbf{0}_{M-1}, 
\mathbf{-1}_{M}, \mathbf{1}_{M-1} ) + \diag \left( \begin{bmatrix}
\mathbf{0}_{M-1}^T &
(1+\overline{\xi} \Delta)^{-1}
\end{bmatrix}^T
\right)
\right] \\
L_{1+}^{B+} &\equiv 
\Delta^{-1}
\left[ 
\text{tridiag}(-\mathbf{0}_{M-1}, 
\mathbf{-1}_{M}, \mathbf{1}_{M-1} ) + \diag \left( \begin{bmatrix}
\mathbf{0}_{M-1}^T &
1- \overline{\xi} \Delta
\end{bmatrix}^T
\right)
\right]
\end{align}
\begin{align}
L_2^{B--} \equiv  \Delta^{-2} 
\Big[ 
&\text{tridiag}(
\mathbf{1}_{M-1},
-2 \times \mathbf{1}_M,
\mathbf{1}_{M-1} )
+ \\
&\diag \left( \begin{bmatrix}
-2 + \underline{\xi}\Delta &
\mathbf{0}_{M-2}^T &
(1+\overline{\xi} \Delta)^{-1}
\end{bmatrix}^T \right)
\Big] \\
L_2^{B-+} \equiv  \Delta^{-2} 
\Big[ 
&\text{tridiag}(
\mathbf{1}_{M-1},
-2 \times \mathbf{1}_M,
\mathbf{1}_{M-1} )
+  \\
&\diag \left( \begin{bmatrix}
-2 + \underline{\xi}\Delta &
\mathbf{0}_{M-2}^T &
-2 - \overline{\xi}\Delta
\end{bmatrix}^T \right)
\Big] \\
L_2^{B+-} \equiv  \Delta^{-2} 
\Big[ 
&\text{tridiag}(
\mathbf{1}_{M-1},
-2 \times \mathbf{1}_M,
\mathbf{1}_{M-1} )
+ \\
&\diag \left( \begin{bmatrix}
-(-1+\underline{\xi} \Delta)^{-1}&
\mathbf{0}_{M-2}^T &
(1+\overline{\xi} \Delta)^{-1}
\end{bmatrix}^T \right)
\Big] \\
L_2^{B++} \equiv  \Delta^{-2} 
\Big[ 
&\text{tridiag}(
\mathbf{1}_{M-1},
-2 \times \mathbf{1}_M,
\mathbf{1}_{M-1} )
+  \\
&\diag \left( \begin{bmatrix}
-(-1+\underline{\xi} \Delta)^{-1}&
\mathbf{0}_{M-2}^T &
-2 - \overline{\xi}\Delta
\end{bmatrix}^T \right)
\Big]
\end{align}

\subsubsection{Absorbing Boundary Conditions}
To apply an absorbing barrier condition $\tilde{v}(x_{\min}) =S$ for some $S \in \mathbb{R}$, with one reflecting barrier condition on the upper bound $v'(x_{\max}) = 0$, one can use

\begin{equation}\label{eq:absorbing-barrier-matrix-lb-regular}
B = \begin{bmatrix}
1 & 0 & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -1 & 1\\
\end{bmatrix}_{2 \times (M+2)} \quad
b = \begin{bmatrix}
S \\
0
\end{bmatrix}
\end{equation}

Similarly, one can apply an absorbing condition on the upper bound  $\tilde{v}(x_{\max}) =S$ for some $S \in \mathbb{R}$ and the


\begin{equation}\label{eq:absorbing-barrier-matrix-ub-regular}
B = \begin{bmatrix}
-1 & 1 & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & 0 & 1\\
\end{bmatrix}_{2 \times (M+2)} \quad
b = \begin{bmatrix}
0 \\
S
\end{bmatrix}
\end{equation}

Note that in the case of $b$ being non-zero, solving the system 
\begin{equation}
\begin{bmatrix}
 L \\
 B
\end{bmatrix} 
\overline{v} 
=
\begin{bmatrix}
f \\
b
\end{bmatrix}
\end{equation}

is not necessarily identical to solving the system
\begin{equation}
R \begin{bmatrix}
 L \\
 B
\end{bmatrix} 
\overline{v}
=
\begin{bmatrix}
f \\
b
\end{bmatrix}
\end{equation}

Consider the case of \cref{eq:absorbing-barrier-matrix-lb-regular} with $S\neq 0$ and $L = L_{1-}$. Adding the first row of $L_{1-}$ by the first row of $B$ multiplied by $\Delta^{-1}$ gives, with the corresponding row operation matrix $R$, 

\begin{equation}
RL_{1-} = \frac{1}{\Delta}\begin{bmatrix}
0&1&0&0&\dots&0&0&0&0\\
0&-1&1&0&\ddots&0&0&0&0\\
\vdots&\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots&\vdots\\
0&0&0&0&\dots&-1&1&0&0\\
0&0&0&0&\cdots&0&-1&1&0
\end{bmatrix}_{M\times (M+2)}
\end{equation}


Then, solving the system 

\begin{equation}
\begin{bmatrix}
 L \\
 B
\end{bmatrix} 
\overline{v}
=
\begin{bmatrix}
f \\
b
\end{bmatrix}
\end{equation}

is identical to solving the system

\begin{align}
R\begin{bmatrix}
 L \\
 B
\end{bmatrix} 
\overline{v}
&= 
R\begin{bmatrix}
f \\
b
\end{bmatrix} \\
&= \begin{bmatrix}
 f(x_1) + \Delta^{-1}S \\
 \vdots \\
 f(x_M) \\
 S \\
 0
\end{bmatrix}
\end{align}

Hence, limited to the interior, solving $v$ in the system above is identical as solving the following system with an operator $L^B$ on interior nodes:
\begin{equation}
L^Bv=\begin{bmatrix}
f(x_1) + \Delta^{-1}S\\
\vdots \\
f(x_M)
\end{bmatrix}
\end{equation}

\section{Discretizing Operators with an Irregular Grid}
\subsection{Discretized Operators}

Define the vectors of backward and forward distance for interior nodes as follows:
\begin{align}
\Delta_{-}^\circ &= \set{\Delta_{i,-}}_{i=1}^M \\
\Delta_{+}^\circ &= \set{\Delta_{i,+}}_{i=1}^M
\end{align}

\paragraph{First Derivative Operators}
To discretize the $\tilde{L}_1$ operator, we can use a backward difference approximation
\begin{align}
\tilde{L}_1 \tilde{v}(x_i) &\equiv \D[x] \tilde{v}(x_i) \approx \frac{\bar{v}_i - \bar{v}_{i-1}}{\Delta_{i,-}},\, \text{ for } i = 1,\ldots, M\label{eq:first-order-bd-irregular}\\
\intertext{And with forward differences}
\tilde{L}_1 \tilde{v}(x_i) &\equiv \D[x] \tilde{v}(x_i) \approx \frac{\bar{v}_{i+1} - \bar{v}_i}{\Delta_{i,+}},\, \text{ for } i = 1,\ldots, M\label{eq:first-order-fd-irregular}
\end{align}

In order to calculate the derivatives for all $i = 1, \ldots, M$ (i.e. in the interior) we can stack these up and apply to the extension $\bar{v}$.
\begin{align}\label{eq:L-1-minus-extended}
{L}_{1-} &\equiv\begin{bmatrix}
-\Delta_{1,-}^{-1}&\Delta_{1,-}^{-1}&0&\dots&0&0&0\\
0&-\Delta_{2,-}^{-1}&\Delta_{2,-}^{-1}&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&\Delta_{M-1,-}^{-1}&0&0\\
0&0&0&\cdots&-\Delta_{M,-}^{-1}&\Delta_{M,-}^{-1}&0
\end{bmatrix}_{M\times (M+2)} \\
&= 
\band^{M,M+2}_{0,1}(-(\Delta_-^\circ)^{-1}, (\Delta_-^\circ)^{-1})
\end{align}

\begin{align}\label{eq:L-1-plus-extended}
{L}_{1+} &\equiv \begin{bmatrix}
0&-\Delta_{1,+}^{-1}&\Delta_{1,+}^{-1}&\dots&0&0&0\\
0&0&-\Delta_{2,+}^{-1}&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&-\Delta_{M-1,+}^{-1}&\Delta_{M-1,+}^{-1}&0\\
0&0&0&\cdots&0&-\Delta_{M,+}^{-1}&\Delta_{M,+}^{-1}&
\end{bmatrix}_{M\times (M+2)} \\
&= 
\band^{M,M+2}_{0,2}(\mathbf{0}_M, -(\Delta_+^\circ)^{-1}, (\Delta_+^\circ)^{-1})
\end{align}

It is important to note that while these operators map the $\bar{v}$ (i.e. including the boundary points), the operator only maps to points on the interior i.e. $i = 1, \ldots, M$.



\paragraph{Second Derivative Operators}
To discretize the $\tilde{L}_2$ second order operator, we can use the following discretization scheme scheme from \cite{achdou17}:
\begin{equation}
v''(x_i) \approx \dfrac{ \Delta_{i,-} \tilde{v}( x_i + \Delta_{i,+}) - (\Delta_{i,+} + \Delta_{i,-}) \tilde{v}( x_i ) + \Delta_{i,+} \tilde{v}( x_i - \Delta_{i,-})}{\frac{1}{2}(\Delta_{i,+} + \Delta_{i,-}) \Delta_{i,+} \Delta_{i,-} }, \text{for } i = 1, \ldots, M
\end{equation}
for second-order derivatives.


In order to calculate the derivatives for all $i = 1, \ldots, M$ (i.e. in the interior) we can stack these up and apply to the extension $\bar{v}$.
\begin{align}\label{eq:L-2-extended} \small
{L}_2 \equiv 2 \begin{psmallmatrix}
(\Delta_{1,+}+\Delta_{1,-})^{-1}\Delta_{1,-}^{-1} &-\Delta_{1,-}^{-1} \Delta_{1,+}^{-1}  & (\Delta_{1,+}+\Delta_{1,-})^{-1} \Delta_{i,+}^{-1}&\dots&0&0\\
0 & \ddots & \ddots &\ddots & 0 & 0\\
\vdots&\ddots &\ddots & \ddots & \ddots & \vdots\\
0&0&\cdots&
(\Delta_{M,+}+\Delta_{M,-})^{-1}\Delta_{M,-}^{-1} &-\Delta_{M,-}^{-1} \Delta_{M,+}^{-1}  &
(\Delta_{M,+}+\Delta_{M,-})^{-1}\Delta_{M,+}^{-1}
\end{psmallmatrix}_{M\times (M+2)} 
\end{align}
which is identical as
\begin{align}
L_2 &= 2 \odot \band_{0,2}^{M,M+2} \left[(\Delta_-^\circ + \Delta_+^\circ)^{-1} \odot (\Delta_{-}^\circ)^{-1}, -(\Delta_-^\circ \odot \Delta_+^\circ)^{-1} , (\Delta_-^\circ + \Delta_+^\circ)^{-1} \odot (\Delta_{+}^\circ)^{-1} \right]
\end{align}


\paragraph{Identity Operators}
Define the identity operator as the $0$-th order operator $\tilde{L}_0 \equiv I$ so that $\tilde{L}_0 \tilde{v}(x) = \tilde{v}(x)$.

With this, the operator applied to the $\bar{v}$ vector is trivial
\begin{align}
\tilde{L}_0 \tilde{v}(x_i) &\equiv \tilde{v}(x_i) = \bar{v}_i,\, \text{ for } i = 1,\ldots, M\
\intertext{And stacking it up for all $i = 1, \ldots, M$,}
\set{\tilde{v}(x_i)}_{i=1}^M &\approx L_0 \cdot \bar{v}
\intertext{Where}
L_0 &\equiv \begin{bmatrix}
0 & 1 & 0 & 0 &\dots & 0 & 0 & 0 &0\\
0 & 0 & 1 & 0 &\dots & 0 & 0 & 0 &0\\
\vdots&\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots&\vdots\\
0 & 0 & 0 & 0 &\dots & 0 & 1 & 0 &0\\
0 & 0 & 0 & 0 &\dots & 0 & 0 & 1 &0
\end{bmatrix}_{M\times (M+2)}\\
&= \begin{bmatrix} \mathbf{0}_M &\mathbf{I}_M & \mathbf{0}_M  \end{bmatrix}\\
&= \band_{0,1}^{M,M+2}(\mathbf{0}_M, \mathbf{1}_M)
\end{align}
which is identical as the identity operator for regular grids.

\subsection{Boundary Conditions}

\subsubsection{Mixed boundary conditions}
Recall mixed boundary conditions from \eqref{eq:mixed-BC1} and \eqref{eq:mixed-BC2}. Note that reflecting barrier conditions are special cases with $\overline{\xi} = \underline{\xi} = 0$. Using forward difference and backward difference discretization scheme for the lower bound and upper bound respectively, we have
\begin{align}
\frac{\overline{v}_1 - \overline{v}_0}{\Delta_{0,+}} + \underline{\xi} \overline{v}_0 &= 0 \label{eq:mixed-BC1-irregular-grid}  \\
\frac{\overline{v}_{M+1} - \overline{v}_M}{\Delta_{M+1,-}} + \overline{\xi} \overline{v}_{M+1} &= 0 \label{eq:mixed-BC2-irregular-grid}
\end{align}

when the drift is positive on the lower bound and is negative on the upper bound. Thus, the corresponding boundary condition matrix $B$ is

\begin{equation}\label{eq:mixed-barrier-matrix-original}
B = \begin{bmatrix}
-\dfrac{1}{\Delta_{0,+}} + \underline{\xi} & \dfrac{1}{\Delta_{0,+}} & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -\dfrac{1}{\Delta_{M+1,-}} & \dfrac{1}{\Delta_{M+1,-}} + \overline{\xi}\\
\end{bmatrix}_{2 \times (M+2)} \quad
b = \begin{bmatrix}
0 \\
0
\end{bmatrix}
\end{equation}
which provides the identical system as
\begin{equation}\label{eq:mixed-barrier-matrix}
B = \begin{bmatrix}
-1 +  \underline{\xi} \Delta_{1,-} & 1 & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -1 & 1 + \overline{\xi} \Delta_{M,+}\\
\end{bmatrix}_{2 \times (M+2)} \quad
b = \begin{bmatrix}
0 \\
0
\end{bmatrix}
\end{equation}
since $\Delta_{0,+} = \Delta_{1,-}$ and $\Delta_{M+1,-} = \Delta_{M,+}$.

Depending on the direction of the drift, the locations of $\overline{\xi}$ and $\underline{\xi}$ have to be different. When the drift is drift is negative on the lower bound and is positive on the upper bound, we have

\begin{align}
&\frac{\overline{v}_1 - \overline{v}_0}{\Delta_{0,+}} + \underline{\xi} \overline{v}_1 = 0 \label{eq:mixed-BC1-irregular-grid-negative}  \\
&\frac{\overline{v}_{M+1} - \overline{v}_M}{\Delta_{M+1,-}} + \overline{\xi} \overline{v}_{M} = 0 \label{eq:mixed-BC2-irregular-grid-positive}
\end{align}

Hence, letting $\circ_1, \circ_M \in \{-, +\}$ denote the drift directions on the lower and upper boundaries respectively, there are four corresponding boundary condition matrices $B^{\circ_1 \circ_M}$ as follows:

\begin{align}
B^{--} &\equiv 
\begin{bmatrix}
-\dfrac{1}{\Delta_{0,+}} & \dfrac{1}{\Delta_{0,+}}  + \underline{\xi} & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -\dfrac{1}{\Delta_{M+1,-}} & \dfrac{1}{\Delta_{M+1,-}} + \overline{\xi}\\
\end{bmatrix}_{2 \times (M+2)} \\
B^{+-} &\equiv 
\begin{bmatrix}
-\dfrac{1}{\Delta_{0,+}} + \underline{\xi} & \dfrac{1}{\Delta_{0,+}} & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -\dfrac{1}{\Delta_{M+1,-}} & \dfrac{1}{\Delta_{M+1,-}} + \overline{\xi}\\
\end{bmatrix}_{2 \times (M+2)} \\
B^{-+} &\equiv 
\begin{bmatrix}
-\dfrac{1}{\Delta_{0,+}}  & \dfrac{1}{\Delta_{0,+}} + \underline{\xi} & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -\dfrac{1}{\Delta_{M+1,-}}+ \overline{\xi} & \dfrac{1}{\Delta_{M+1,-}}\\
\end{bmatrix}_{2 \times (M+2)} \\
B^{++} &\equiv 
\begin{bmatrix}
-\dfrac{1}{\Delta_{0,+}} + \underline{\xi} & \dfrac{1}{\Delta_{0,+}} & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -\dfrac{1}{\Delta_{M+1,-}}+ \overline{\xi} & \dfrac{1}{\Delta_{M+1,-}} \\
\end{bmatrix}_{2 \times (M+2)}
\end{align}

Multiplying the first rows by $\Delta_{1,-} = \Delta_{0,+}$ and second rows by $\Delta_{M,+} = \Delta_{M+1,-} $, the resulting system has the same $b$ and the following $B^{--}, B^{+-}, B^{-+}, B^{++}$:

\begin{align}
B^{--} &\equiv 
\begin{bmatrix}
-1 & 1  + \underline{\xi}\Delta_{1,-} & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -1 & 1 + \overline{\xi}\Delta_{M,+}\\
\end{bmatrix}_{2 \times (M+2)} \\
B^{+-} &\equiv 
\begin{bmatrix}
-1 + \underline{\xi}\Delta_{1,-} & 1 & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -1 & 1 + \overline{\xi}\Delta_{M,+}\\
\end{bmatrix}_{2 \times (M+2)} \\
B^{-+} &\equiv 
\begin{bmatrix}
-1  & 1 + \underline{\xi}\Delta_{1,-} & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -1+ \overline{\xi}\Delta_{M,+} & 1\\
\end{bmatrix}_{2 \times (M+2)} \\
B^{++} &\equiv 
\begin{bmatrix}
-1 + \underline{\xi}\Delta_{1,-} & 1 & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -1+ \overline{\xi}\Delta_{M,+} & 1 \\
\end{bmatrix}_{2 \times (M+2)}
\end{align}


\subsubsection{Reflecting Barriers}
Since a reflecting barrier (i.e. a Neumann boundary condition) is a special case of the mixed when  $\underline{\xi} = \bar{\xi} = 0$, the $B$ matrix for a reflecting barrier follows \cref{eq:B-mixed}
\begin{equation}
B = \begin{bmatrix}
-1& 1 & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -1 & 1\\
\end{bmatrix}_{2 \times (M+2)}
\end{equation}
with the same 
\begin{equation}
	b = \begin{bmatrix}	
			0 \\
		 	0
		 	\end{bmatrix}
\end{equation}

Note that this does not depend on the direction of the drift as $B^{--} = B^{+-} = B^{-+} = B^{++}$ when $\overline{\xi} = \underline{\xi} = 0$.

\subsubsection{Absorbing Barriers}

With the homogenous or inhomogeneous Dirichlet Boundary Conditions in \cref{eq:absorbing-BC1,eq:absorbing-BC2}, in operator form,
\begin{align}
\tilde{B} &\equiv \begin{bmatrix}
1 \vert_{x = x_{\min}}\\
1 \vert_{x = x_{\max}}
\end{bmatrix}
\end{align}

Implementing this for the system in \cref{eq:BC-system} gives,

\begin{align}
B &= \begin{bmatrix}
1 & 0 & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & 0 & 1\\
\end{bmatrix}_{2 \times (M+2)}\\
b &= \begin{bmatrix}
b_1 \\
b_2
\end{bmatrix}
\end{align}
which is identical as \eqref{eq:absorbing-barrier-matrix-regular} for regular grids.

\subsection{Applying Boundary Conditions to Operators}\label{subsec:applying-bc}
Instead of solving \eqref{eq:reflecting-barrier-extended-system} for a value function $\tilde{v}(\overline{x})$ on the extended grid, one can perform Gaussian elimination to reduce the system and solve $\tilde{v}(x)$, which gives the identical solution as the interior of $\tilde{v}(\overline{x})$.



\subsubsection{Mixed boundary conditions}\label{subsubsec-irregular-grids-mixed-boundary-conditions}

The first columns of all the extension operators above, ${L}_{1-}, {L}_{1+}, {L}_{2}, {I}$, have non-zero element only in the first rows. Thus, a single Gaussian elimination for the first extension grid will suffice to remove the extended grid point. Likewise, in the last columns of all the extension operators have non-zero element only in the last row.


Adding the first row of $L_{1-}$ by the first row of $B$ in \eqref{eq:mixed-barrier-matrix} multiplied by $(-1 + \underline{\xi} \Delta_{1,-} )^{-1}\Delta_{1,-}^{-1}$ gives, with the corresponding row operation matrix $R$ for Gaussian elimination,

\begin{equation}
R {L}_{1-} = \begin{bmatrix}
0&\Delta_{1,-}^{-1} \left[ 1 + (-1+\underline{\xi} \Delta_{1,-} )^{-1} \right] &0&\dots&0&0&0\\
0&-\Delta_{2,-}^{-1}&\Delta_{2,-}^{-1}&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&\Delta_{M-1,-}^{-1}&0&0\\
0&0&0&\cdots&-\Delta_{M,-}^{-1}&\Delta_{M,-}^{-1}&0
\end{bmatrix}_{M\times (M+2)}
\end{equation}
note that there is no zero element in the first and last column for nodes on boundaries. Hence, solving the corresponding extended system,
\begin{align}
\begin{bmatrix}
{L}\\
B
\end{bmatrix} 
\overline{v}
=
\begin{bmatrix}
f \\ b
\end{bmatrix}
\end{align}
is identical as solving the following system
\begin{align}
R
\begin{bmatrix}
{L}\\
B
\end{bmatrix} 
\overline{v}
&=
R
\begin{bmatrix}
f \\ b
\end{bmatrix} \\
&= \begin{bmatrix}
f \\ b
\end{bmatrix}
\end{align}
as $b$ is a zero vector so that the row operations $R$ do not change anything on the RHS. Furthermore, limited to the interior, solving $v$ in the system above is identical as solving the following system with an operator $L^B$ on interior nodes:
\begin{equation}
L^B v = f
\end{equation}
where we have ${L} = {L}_{1-}$ and $L^B = L_{1-}^B$ with
\begin{equation}
L_{1-}^B \equiv \begin{bmatrix}
\Delta_{1,-}^{-1} [1 + (-1 + \underline{\xi} \Delta_{1,-})^{-1}] &0&0&\dots&0&0&0\\
-\Delta_{2,-}^{-1}&\Delta_{2,-}^{-1}&0&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&-\Delta_{M-1,-}^{-1}&\Delta_{M-1,-}^{-1}&0\\
0&0&0&\cdots&0&-\Delta_{M,-}^{-1}&\Delta_{M,-}^{-1}
\end{bmatrix}_{M\times M}
\end{equation}
instead of solving the full system with boundary conditions. Similarly, subtracting the last row of $L_{1+}$ by the second row of $B$ in \eqref{eq:mixed-barrier-matrix} multiplied by $(1 + \overline{\xi} \Delta_{M,+})^{-1} \Delta_{M,+}^{-1}$ gives the following differential operator with the boundary condition $B$ applied:
\begin{align}
L_{1+}^B &\equiv \begin{bmatrix}
-\Delta_{1,+}^{-1}&\Delta_{1,+}^{-1}&0&\dots&0&0&0\\
0&-\Delta_{2,+}^{-1}&\Delta_{2,+}^{-1}&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\cdots&0&-\Delta_{M-1,+}^{-1}&\Delta_{M-1,+}^{-1}\\
0&0&0&\dots&0&0&\Delta_{M,+}^{-1}  [-1 + (1 + \overline{\xi} \Delta_{M,+})^{-1}]  \\
\end{bmatrix}_{M\times M}\label{eq:L-1-plus}
\end{align}
And by substracting the first row of $L_2$ by the first row of $B$ multiplied by $2(-1 + \underline{\xi} \Delta_{1,-} )^{-1} (\Delta_{1,+} + \Delta_{1,-})^{-1}  \Delta_{1,-}^{-1} $ and the last row of $L_2$ by the second row of $B$ multiplied by $2(1 + \overline{\xi} \Delta_{M,+} )^{-1} (\Delta_{M,+} + \Delta_{M,-})^{-1}  \Delta_{M,+}^{-1}$, we have the following differential operator with the boundary condition $B$ applied for $L_2$:
\begin{align}
L_2^B &\equiv 2 \begin{psmallmatrix}
\Xi_1 &
(\Delta_{1,+}+\Delta_{1,-})^{-1} \Delta_{1,+}^{-1}
&0&\cdots&0&0&0 \\
\vdots&\ddots&\ddots&\ddots&\ddots&\vdots&\vdots\\
0&\cdots&
(\Delta_{i,+}+\Delta_{i,-})^{-1} \Delta_{i,-}^{-1} &
-\Delta_{i,-}^{-1} \Delta_{i,+}^{-1}  &
 (\Delta_{i,+}+\Delta_{i,-})^{-1} \Delta_{i,+}^{-1}&\cdots&0 \\
\vdots&\vdots&\vdots&\ddots&\ddots&\ddots&\vdots\\
0&0&0&\cdots&0&(\Delta_{M,+}+\Delta_{M,-})^{-1} \Delta_{M,-}^{-1}&\Xi_M
\end{psmallmatrix}_{M\times M}\label{eq:L-2} 
\end{align}
where

\begin{align}
\Xi_{1} &= - (-1 + \underline{\xi} \Delta_{1,-})^{-1} (\Delta_{1,+} + \Delta_{1,-})^{-1}  \Delta_{1,-}^{-1} \\
\Xi_{M} &=  (1 + \overline{\xi} \Delta_{M,+})^{-1} (\Delta_{M,+} + \Delta_{M,-})^{-1}  \Delta_{M,+}^{-1} 
\end{align}

Note that the interior of the identity operator is invariant even after applying the mixed boundary conditions, as the columns for the boundary (the first and last column) are all empty. Hence, we have:

\begin{align}
I^B &\equiv \begin{bmatrix}
1 & 0 & \cdots & 0 & 0 \\
0 & 1 & \cdots & 0 & 0 \\
\vdots  & \ddots & \ddots &  \vdots  & \vdots   \\
0 & 0 & \cdots & 1 & 0 \\
0 & 0 & \cdots & 0 & 1
\end{bmatrix}_{M\times M}
\end{align}



Alternatively, with vectorized differences, we can express the differential operators with boundary conditions applied on the interior nodes as follows:


\begin{align}
{L}_{1-}^B \equiv
\tridiag \left(-(\Delta_-^\circ)^{-1}[2:M], (\Delta_-^\circ )^{-1}, \mathbf{0}_{M-1}  \right) +
\diag\left( 
\begin{bmatrix}
\Delta^{-1}_{1,-} (-1 + \underline{\xi} \Delta_{1,-})^{-1} &
\mathbf{0}_{M-1}^T
\end{bmatrix}^T
 \right)
\end{align}

\begin{align}
{L}_{1+}^B \equiv
\tridiag \left(\mathbf{0}_{M-1}, -(\Delta_+^\circ )^{-1}, (\Delta_+^\circ)^{-1}[2:M]  \right) +
\diag\left( 
\begin{bmatrix}
\mathbf{0}_{M-1}^T &
\Delta^{-1}_{M,+} (1 + \overline{\xi} \Delta_{M,+})^{-1}
\end{bmatrix}^T
\right)
\end{align}

\begin{align}
{L}_{2}^B \equiv
2 \odot \Big[ & \text{tridiag} \Big[(\Delta_-^\circ + \Delta_+^\circ)^{-1} \odot (\Delta_{-}^\circ)^{-1}, 
-(\Delta_-^\circ \odot \Delta_+^\circ)^{-1},
(\Delta_-^\circ + \Delta_+^\circ)^{-1} \odot (\Delta_{+}^\circ)^{-1} \Big] + \\ & \diag\left(  
\begin{bmatrix} \
\Xi_1 & \mathbf{0}_{M-2} & \Xi_M
\end{bmatrix}
  \right) \Big]
\end{align}

\begin{align}
I^B \equiv  \text{diag($\mathbf{1}_M$)}
\end{align}


\paragraph{Applying drift directions on boundary conditions}
Adding the first row of $B^{--}$ or $B^{-+}$ multiplied by $\Delta_{1,-}^{-1}$ on the first row of $L_{1-}$ and extracting the interior yields

\begin{equation}
L_{1-}^{B-} \equiv \begin{bmatrix}
-\underline{\xi} \Delta_{1,-} &0&0&\dots&0&0&0\\
-\Delta_{2,-}^{-1}&\Delta_{2,-}^{-1}&0&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&-\Delta_{M-1,-}^{-1}&\Delta_{M-1,-}^{-1}&0\\
0&0&0&\cdots&0&-\Delta_{M,-}^{-1}&\Delta_{M,-}^{-1}
\end{bmatrix}_{M\times M}
\end{equation}

Likewise,
Adding the first row of $B^{-+}$ or $B^{++}$ multiplied by $\Delta_{M,+}^{-1}$ on the first row of $L_{1+}$ and extracting the interior yields

\begin{equation}
L_{1+}^{B+} \equiv \begin{bmatrix}
-\Delta_{1,+}^{-1}&\Delta_{1,+}^{-1}&0&\dots&0&0&0\\
0&-\Delta_{2,+}^{-1}&\Delta_{2,+}^{-1}&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\cdots&0&-\Delta_{M-1,+}^{-1}&\Delta_{M-1,+}^{-1}\\
0&0&0&\cdots&0&0&-\overline{\xi} \Delta_{M,+}
\end{bmatrix}_{M\times M} \label{eq:L-1p-irregular-right}
\end{equation}

For $L_2$, directions on both boundaries affect the interior. Here we study the two upper and lower boundaries separately. For the lower boundary, suppose first that the drift is positive. Substracting the first row of $L_2$ by the first row of $B^{+-}$ or $B^{++}$ multiplied by $2(-1 + \underline{\xi} \Delta_{1,-} )^{-1} (\Delta_{1,+} + \Delta_{1,-})^{-1}  \Delta_{1,-}^{-1} $  and extracting the interior and first row gives
\begin{align}
2\begin{bmatrix}
\Xi_{1+} &1&0&\dots&0&0&0
\end{bmatrix}_{1\times M}
\end{align}
where $\Xi_{1+} \equiv  - (-1 + \underline{\xi} \Delta_{1,-})^{-1} (\Delta_{1,+} + \Delta_{1,-})^{-1}  \Delta_{1,-}^{-1}$.

Suppose that we have a negative drift at the lower boundary. Adding the first row of $L_2$ by the first row of $B^{--}$ or $B^{-+}$ multiplied by $2(\Delta_{1,+} + \Delta_{1,-} )^{-1} \Delta_{1,-}^{-1}$ and extracting the interior and first row gives
\begin{align}
2\begin{bmatrix}
\Xi_{1-} &1&0&\dots&0&0&0
\end{bmatrix}_{1\times M}
\end{align}
where $\Xi_{1-} \equiv -\Delta_{1,-}^{-1} \Delta_{1,+}^{-1}  + (\Delta_{1,+} + \Delta_{1,-} )^{-1} \Delta_{1,-}^{-1} (1 + \underline{\xi}\Delta_{1,-})$.
Now consider the upper boundary. Suppose first that the drift is negative. Substracting the last row of $L_2$ by the second row of $B^{--}$ or $B^{+-}$ multiplied by $2(1 + \overline{\xi} \Delta_{M,+} )^{-1} (\Delta_{M,+} + \Delta_{M,-})^{-1}  \Delta_{M,+}^{-1}$ and extracting the interior and last row gives 
\begin{align}
2\begin{bmatrix}
0 &0&0&\dots&0&1&\Xi_{M-}
\end{bmatrix}_{1\times M}
\end{align}

where $\Xi_{M-} = (1 + \overline{\xi} \Delta_{M,+})^{-1} (\Delta_{M,+} + \Delta_{M,-})^{-1}  \Delta_{M,+}^{-1}$. Suppose that we have a positive drift at the upper boundary. Subtracting the second row of $L_2$ by the first row of $B^{-+}$ or $B^{++}$ multiplied by $2(\Delta_{M,+} + \Delta_{M,-})^{-1} \Delta_{M,+}^{-1} $ and extracting the interior and last row gives
\begin{align}
2\begin{bmatrix}
0 &0&0&\dots&0&1&\Xi_{M+}
\end{bmatrix}_{1\times M}
\end{align}
where $\Xi_{M+} = -\Delta_{M,-}^{-1} \Delta_{M,+}^{-1} - ( \Delta_{M,+} + \Delta_{M,-} )^{-1} \Delta_{M,+}^{-1} (-1 + \overline{\xi} \Delta_{M,+})  $.

This provides the complete combination of all possible drift directions on both boundaries for $L_2$. For instance, $L_2^{B-+}$ is defined as
\begin{align}
L_2^{B-+} &\equiv  2 \begin{psmallmatrix}
\Xi_{1-} &
(\Delta_{1,+}+\Delta_{1,-})^{-1} \Delta_{1,+}^{-1}
&0&\cdots&0&0&0 \\
\vdots&\ddots&\ddots&\ddots&\ddots&\vdots&\vdots\\
0&\cdots&
(\Delta_{i,+}+\Delta_{i,-})^{-1} \Delta_{i,-}^{-1} &
-\Delta_{i,-}^{-1} \Delta_{i,+}^{-1}  &
(\Delta_{i,+}+\Delta_{i,-})^{-1} \Delta_{i,+}^{-1}&\cdots&0 \\
\vdots&\vdots&\vdots&\ddots&\ddots&\ddots&\vdots\\
0&0&0&\cdots&0&(\Delta_{M,+}+\Delta_{M,-})^{-1} \Delta_{M,-}^{-1}&\Xi_{M+}
\end{psmallmatrix}_{M\times M}
\end{align}



Using banded matrices, these operators can be definied in the following compact forms:


\begin{align}
{L}_{1-}^{B-} &\equiv
\tridiag \left(-(\Delta_-^\circ)^{-1}[2:M], (\Delta_-^\circ )^{-1}, \mathbf{0}_{M-1}  \right) +
\diag\left( 
\begin{bmatrix}
(-\Delta^{-1}_{1,-} - \underline{\xi} \Delta_{1,-}) &
\mathbf{0}_{M-1}^T
\end{bmatrix}^T
\right) \\
{L}_{1-}^{B+} &\equiv
\tridiag \left(-(\Delta_-^\circ)^{-1}[2:M], (\Delta_-^\circ )^{-1}, \mathbf{0}_{M-1}  \right) +
\diag\left( 
\begin{bmatrix}
\Delta^{-1}_{1,-} (-1 + \underline{\xi} \Delta_{1,-})^{-1} &
\mathbf{0}_{M-1}^T
\end{bmatrix}^T
\right)
\end{align}
\begin{align}
{L}_{1+}^{B-} &\equiv
\tridiag \left(\mathbf{0}_{M-1}, -(\Delta_+^\circ )^{-1}, (\Delta_+^\circ)^{-1}[2:M]  \right) +
\diag\left( 
\begin{bmatrix}
\mathbf{0}_{M-1}^T &
\Delta^{-1}_{M,+} (1 + \overline{\xi} \Delta_{M,+})^{-1}
\end{bmatrix}^T
\right) \\
{L}_{1+}^{B+} &\equiv
\tridiag \left(\mathbf{0}_{M-1}, -(\Delta_+^\circ )^{-1}, (\Delta_+^\circ)^{-1}[2:M]  \right) +
\diag\left( 
\begin{bmatrix}
\mathbf{0}_{M-1}^T &
(\Delta^{-1}_{M,+} - \overline{\xi} \Delta_{M,+})
\end{bmatrix}^T
\right) 
\end{align}
\begin{align}
{L}_{2}^{B \circ_1 \circ_M } \equiv
2 \odot \Big[ & \text{tridiag} \Big[(\Delta_-^\circ + \Delta_+^\circ)^{-1} \odot (\Delta_{-}^\circ)^{-1}, 
-(\Delta_-^\circ \odot \Delta_+^\circ)^{-1},
(\Delta_-^\circ + \Delta_+^\circ)^{-1} \odot (\Delta_{+}^\circ)^{-1} \Big] + \\ & \diag\left(  
\begin{bmatrix} \
\Xi_{1 \circ_1} & \mathbf{0}_{M-2} & \Xi_{M \circ_M}
\end{bmatrix}
\right) \Big]
\end{align}
where $\circ_1, \circ_M \in \{-, +\}$ denote the drift directions on the lower and upper boundaries respectively.


\subsubsection{Absorbing barrier conditions}

To apply an absorbing barrier condition $\tilde{v}(x_{\min}) =S$ for some $S \in \mathbb{R}$, with one reflecting barrier condition on the upper bound $v'(x_{\max}) = 0$, one can use

\begin{equation}\label{eq:absorbing-barrier-matrix}
B = \begin{bmatrix}
1 & 0 & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & -1 & 1\\
\end{bmatrix}_{2 \times (M+2)} \quad
b = \begin{bmatrix}
S \\
0
\end{bmatrix}
\end{equation}

Similarly, one can apply an absorbing condition on the upper bound  $\tilde{v}(x_{\max}) =S$ for some $S \in \mathbb{R}$ and the


\begin{equation}\label{eq:absorbing-barrier-matrix-ub}
B = \begin{bmatrix}
-1 & 1 & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 0 & \dots & 0 & 0 & 1\\
\end{bmatrix}_{2 \times (M+2)} \quad
b = \begin{bmatrix}
0 \\
S
\end{bmatrix}
\end{equation}

Note that the corresponding $B$ and $b$ are identical with regular grid cases. Furthermore, note that in the case of $b$ being non-zero, solving the system 
\begin{equation}
\begin{bmatrix}
 L \\
 B
\end{bmatrix} 
\overline{v}
=
\begin{bmatrix}
f \\
b
\end{bmatrix}
\end{equation}

is not necessarily identical to solving the system
\begin{equation}
R \begin{bmatrix}
 L \\
 B
\end{bmatrix} 
\overline{v}
=
\begin{bmatrix}
f \\
b
\end{bmatrix}
\end{equation}


Consider the case of \cref{eq:absorbing-barrier-matrix} with $S\neq 0$ and $L = L_{1-}$. Adding the first row of $L_{1-}$ by the first row of $B$ multiplied by $\Delta_{1,-}^{-1}$ gives, with the corresponding row operation matrix $R$, 

\begin{equation}
R {L}_{1-} = \begin{bmatrix}
0&\Delta_{1,-}^{-1} &0&\dots&0&0&0\\
0&-\Delta_{2,-}^{-1}&\Delta_{2,-}^{-1}&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&\Delta_{M-1,-}^{-1}&0&0\\
0&0&0&\cdots&-\Delta_{M,-}^{-1}&\Delta_{M,-}^{-1}&0
\end{bmatrix}_{M\times (M+2)}
\end{equation}

Then, solving the system 

\begin{equation}
\begin{bmatrix}
 L \\
 B
\end{bmatrix} 
\overline{v} 
=
\begin{bmatrix}
f \\
b
\end{bmatrix}
\end{equation}

is identical to solving the system

\begin{align}
R\begin{bmatrix}
 L \\
 B
\end{bmatrix} 
\overline{v}
&= 
R\begin{bmatrix}
f \\
b
\end{bmatrix} \\
&= \begin{bmatrix}
 f(x_1) + \Delta_{1,-}^{-1}S \\
 \vdots \\
 f(x_M) \\
 S \\
 0
\end{bmatrix}
\end{align}

Hence, limited to the interior, solving $v$ in the system above is identical as solving the following system with an operator $L^B$ on interior nodes:
\begin{equation}
L^Bv=\begin{bmatrix}
f(x_1) + \Delta_{1,-}^{-1}S\\
\vdots \\
f(x_M)
\end{bmatrix}
\end{equation}


\subsection{Examples}

\begin{example}\label{ex:gaussian-elimination-reflecting-barrier}
	Consider $L = L_{2}$ to solve $L v = f$ with $M = 3$ under uniform grids $\overline{x} = \{x_0, x_1, x_2, x_3, x_4\}$ and $\Delta = 1$, whose corresponding interior grid is $x = \{x_1, x_2, x_3\}$. This gives
	\begin{align}
	L^B = 	 \begin{bmatrix}
	-1 & 1 & 0 \\
	1 & -2 & 1 \\
	0 & 1 & -1 \\
	\end{bmatrix}
	\end{align}
	so $L^B v= f$ on the grid $x$ results in the following system
	\begin{align} \label{eq:extended-system-reflecting-barrier-reduced-system}
	\begin{bmatrix}
	-1 & 1 & 0  \\
	1 & -2 & 1 \\
	0 & 1 & -1 \\
	\end{bmatrix} 	  \begin{bmatrix}
	\tilde{v}(x_1) \\
	\tilde{v}(x_2) \\
	\tilde{v}(x_3)
	\end{bmatrix}
	=
	\begin{bmatrix}
	\tilde{f}(x_1) \\
	\tilde{f}(x_2) \\
	\tilde{f}(x_3)
	\end{bmatrix}
	\end{align}


	For the extended system we have
	\begin{align}
	{L} &=
	\begin{bmatrix}
	1 & -2 & 1 & 0 & 0 \\
	0 & 1 & -2 & 1 & 0 \\
	0 & 0 & 1 & -2 & 1 \\
	\end{bmatrix} \\
	B &= \begin{bmatrix}
	-1 & 1  & 0 & 0 & 0 \\
	0 & 0 & 0 & -1 & 1
	\end{bmatrix}
	\end{align}

	Constructing the stacked extended system \eqref{eq:reflecting-barrier-extended-system} gives
	\begin{align}\label{eq:extended-system-reflecting-barrier-before-gaussian-elimination}
	\begin{bmatrix}
	1 & -2 & 1 & 0 & 0 \\
	0 & 1 & -2 & 1 & 0 \\
	0 & 0 & 1 & -2 & 1 \\
	-1 & 1  & 0 & 0 & 0 \\
	0 & 0 & 0 & -1 & 1
	\end{bmatrix}
	\begin{bmatrix}
	\tilde{v}(x_0) \\
	\tilde{v}(x_1) \\
	\tilde{v}(x_2) \\
	\tilde{v}(x_3) \\
	\tilde{v}(x_4)
	\end{bmatrix}
	=
	\begin{bmatrix}
	\tilde{f}(x_1) \\
	\tilde{f}(x_2) \\
	\tilde{f}(x_3) \\
	0 \\
	0
	\end{bmatrix}
	\end{align}

	Note that substracting the first row of ${L}$ by $(-1)$ times the first row of $B$ returns an identical system as \eqref{eq:extended-system-reflecting-barrier-before-gaussian-elimination}. Likewise, substracting the last row of ${L}$ by $(-1)$ times the last row of $B$ returns the identical system. Performing the two Gaussian elimination yields the following system:
	\begin{align}\label{eq:extended-system-reflecting-barrier-after-gaussian-elimination}
	\begin{bmatrix}
	0 & -1 & 1 & 0 & 0 \\
	0 & 1 & -2 & 1 & 0 \\
	0 & 0 & 1 & -1 & 0 \\
	1 & -1  & 0 & 0 & 0 \\
	0 & 0 & 0 & -1 & 1
	\end{bmatrix} 	  \begin{bmatrix}
	\tilde{v}(x_0) \\
	\tilde{v}(x_1) \\
	\tilde{v}(x_2) \\
	\tilde{v}(x_3) \\
	\tilde{v}(x_4)  \\
	\end{bmatrix}
	=
	\begin{bmatrix}
	\tilde{f}(x_2) \\
	\tilde{f}(x_3) \\
	\tilde{f}(x_4) \\
	0 \\
	0
	\end{bmatrix}
	\end{align}
	Note that now we have the first three rows of the coefficient matrix with zero columns on the extended nodes, $\tilde{v}(x_1 - \Delta)$ and $\tilde{v}(x_3 + \Delta)$. Extracting the system corresponding to the first three rows returns the following system, which solves the interior of $\bar{v}$, i.e., $v$:
	\begin{align}
	\begin{bmatrix}
	-1 & 1 & 0  \\
	1 & -2 & 1 \\
	0 & 1 & -1 \\
	\end{bmatrix} 	  \begin{bmatrix}
	\tilde{v}(x_1) \\
	\tilde{v}(x_2) \\
	\tilde{v}(x_3)
	\end{bmatrix}
	=
	\begin{bmatrix}
	\tilde{f}(x_1) \\
	\tilde{f}(x_2) \\
	\tilde{f}(x_3)
	\end{bmatrix}
	\end{align}
	which is identical as  \eqref{eq:extended-system-reflecting-barrier-reduced-system}.
\end{example}

\begin{example}
	Consider solving \eqref{eq:extended-system-reflecting-barrier-reduced-system}, but this time with an absorbing barrier condition on the lower bound, $\tilde{v}(x_{\min}) = S$ with a boundary condition matrix
	\begin{align}
	B &= \begin{bmatrix}
	1 & 0  & 0 & 0 & 0 \\
	0 & 0 & 0 & -1 & 1
	\end{bmatrix}
	\end{align}
	The corresponding extended system is
	\begin{align}\label{eq:extended-system-absorbing-barrier-before-gaussian-elimination}
	\begin{bmatrix}
	1 & -2 & 1 & 0 & 0 \\
	0 & 1 & -2 & 1 & 0 \\
	0 & 0 & 1 & -2 & 1 \\
	1 & 0  & 0 & 0 & 0 \\
	0 & 0 & 0 & -1 & 1
	\end{bmatrix}
	\begin{bmatrix}
	\tilde{v}(x_0) \\
	\tilde{v}(x_1) \\
	\tilde{v}(x_2) \\
	\tilde{v}(x_3) \\
	\tilde{v}(x_4) \\
	\end{bmatrix}
	=
	\begin{bmatrix}
	\tilde{f}(x_1) \\
	\tilde{f}(x_2) \\
	\tilde{f}(x_3) \\
	S \\
	0
	\end{bmatrix}
	\end{align}

	Note that substracting the first row of ${L}$ by $(-1)$ times the first row of $B$ returns an identical system as \eqref{eq:extended-system-absorbing-barrier-before-gaussian-elimination}. Likewise, substracting the last row of ${L}$ by $(-1)$ times the last row of $B$ returns the identical system. Performing the two Gaussian elimination yields the following system:
	\begin{align}\label{eq:extended-system-absorbing-barrier-after-gaussian-elimination}
	\begin{bmatrix}
	0 & -2 & 1 & 0 & 0 \\
	0 & 1 & -2 & 1 & 0 \\
	0 & 0 & 1 & -1 & 0 \\
	1 & 0  & 0 & 0 & 0 \\
	0 & 0 & 0 & -1 & 1
	\end{bmatrix} 	  \begin{bmatrix}
	\tilde{v}(x_0) \\
	\tilde{v}(x_1) \\
	\tilde{v}(x_2) \\
	\tilde{v}(x_3) \\
	\tilde{v}(x_4) \\
	\end{bmatrix}
	=
	\begin{bmatrix}
	\tilde{f}(x_1) - S \\
	\tilde{f}(x_2) \\
	\tilde{f}(x_3) \\
	0 \\
	0
	\end{bmatrix}
	\end{align}

	Extracting the system corresponding to the first three rows returns the following system, which solves the interior of $\bar{v}$, i.e., $v$:
	\begin{align}
	\begin{bmatrix}
	-2 & 1 & 0  \\
	1 & -2 & 1 \\
	0 & 1 & -1 \\
	\end{bmatrix} 	  \begin{bmatrix}
	\tilde{v}(x_1) \\
	\tilde{v}(x_2) \\
	\tilde{v}(x_3)
	\end{bmatrix}
	=
	\begin{bmatrix}
	\tilde{f}(x_1) - S \\
	\tilde{f}(x_2) \\
	\tilde{f}(x_3)
	\end{bmatrix}
	\end{align}
\end{example}
%
% \section{Applications}
%
% \subsection{Hamilton–Jacobi–Bellman equations (HJBE)}
% Consider solving for $v$ from the following optimal control problem
% \begin{align}
% \tilde{v}(x_0) = \max_{ {\{\alpha(t) \} }_{t \geq 0} } \int_{0}^\infty e^{-\rho t} r( x(t), \alpha(t )) dt
% \end{align}
%
% with the law of motion for the state
% \begin{align}
% dx = \mu dt + \sigma dW
% \end{align}
%
%
% for some constant $\mu \geq 0$ and $\sigma \geq 0$ with $x(0) = x_0$.
%
% Let $\alpha^*(t)$ be the optimal solution. Suppose that $r$ under $\alpha^*(t)$ can be expressed in terms of state variables, $r^* (x)$. Then, the HJBE yields
%
% \begin{equation}\label{eq:hamilton-jacobi-bellman}
% \rho \tilde{v}(x) = r^*(x) +  \mu  \partial_{x} \tilde{v}(x) + \dfrac{\sigma^2}{2} \partial_{xx} \tilde{v}(x)
% \end{equation}
%
% In terms of differential operators, one can rewrite the equation as
% \begin{equation}\label{eq:hjbe-system-function}
% \tilde{L}  \tilde{v}(x) = r^*(x)
% \end{equation}
%
% with $\tilde{L} = \rho -  \tilde{L}_x$ where $\tilde{L}_x$ is defined as
%
% \begin{equation}\label{eq:L-defn}
% \tilde{L}_x = \mu \partial_{x} + (\sigma^2/2) \partial_{xx}
% \end{equation}
%
%
% By descretizing the space of $x$, one can solve the corresponding system by using discretized operators for $\partial_{x}$ ($L_{1+}$), $\partial_{xx}$ ($L_2$) on some grids of length $M$, $\{x_i\}_{i=1}^M$:
% \begin{align}\label{eq:L-descritized-defn}
% L_x = \mu L_{1+} + \dfrac{\sigma^2}{2} L_{2}
% \end{align}
% so that $v$ from \eqref{eq:hjbe-system-function} can be computed by solving the following discretized system of equations:
% \begin{align}
% L v &= r^*
% \end{align}
% where $v$ and $r^*$ are $M$-vectors whose $i$th elements are $\tilde{v}(x_i)$ and $r^*(x_i)$, respectively, and $L$ is defined as $L = \rho I - L_x$.
%
%
%
% \subsection{Kolmogorov forward equations (KFE) under diffusion process}
% Let $g(x, t)$ be the distribution of $x$ at time $t$ from the example above. By the Kolmogorov forward equation, the following PDE holds:
%
% \begin{equation}\label{eq:kfe}
% \partial_{t} g(x, t) = - \mu \partial_{x}  g(x,t) + \dfrac{\sigma^2}{2} \partial_{xx} g(x,t)
% \end{equation}
%
% \subsubsection{Stationary distributions}
% The stationary distribution $g^*(x)$ satisfies
%
% \begin{equation}\label{eq:kfe-stationary}
% 0 = - \mu \partial_{x} g^*(x) + \dfrac{\sigma^2}{2} \partial_{xx} g^*(x)
% \end{equation}
%
% which can be rewritten as
%
% \begin{equation}
% \tilde{L}^*_x g(x) = 0
% \end{equation}
%
% where
%
% \begin{equation}\label{eq:L_star-defn}
% \tilde{L}^*_x =  - \mu \partial_{x} + (\sigma^2/2) \partial_{xx}
% \end{equation}
%
% By descretizing the space of $x$, one can solve the corresponding system by using discretized operators for $\tilde{L}^*_x$. Note that the operator for the KFE in \eqref{eq:L_star-defn} is the adjoint operator of the operator for the HJBE in \eqref{eq:L-defn}, and the correct discretization scheme for \eqref{eq:L_star-defn} can be, analogously, done by taking the transpose of the discretized operator for HJBE in \eqref{eq:L-descritized-defn} -- see \cite{gabaix16} and \cite{achdou17}. Hence, one can find the stationary distribution by solving the following discretized system of equations:
%
% \begin{equation}
% L^T_x g = 0
% \end{equation}
% where $L^T_x$ is the transpose of $L_x$ from \eqref{eq:L-descritized-defn} and $g$ is an $M$-vector whose element is $g(x_i)$ such that $\sum_{i=1}^M g(x_i) = 1$.
%
% \subsubsection{Full dynamics of distributions}
% One can also solve the full PDE in \eqref{eq:kfe}, given an initial distribution $g(x, 0)$. After discretization, note that \eqref{eq:kfe} can be rewritten as
% \begin{equation}\label{eq:kfe-discretized}
% \dot{g}(t) = L^T_x g(t)
% \end{equation}
% where $\dot{g}(t)$ is an $M$-vector whose $i$th element is $\partial_{t} g(x_i, t)$, which can be efficently solved by a number of differential equation solvers available in public, including \cite{rackauckas17}.

\newpage

\appendix

\section{Special Matrices and Notation}\label{sec:special-matrices}
In the code and algebra, a number of the matrices for discretization have special structure.
\paragraph{Toeplitz Matrices}
First, a Toeplitz matrix is one in which every descending diagonal is constant.  See \url{https://en.wikipedia.org/wiki/Toeplitz_matrix} for more examples and theory. To create, you need to specify the lower off-diagonals (ordered by rows) and the upper off-diagonals (ordered by columns).  They are square only if the number of rows and columns passed in is identical.\footnote{This notation is intended to match Matlab's and Julia's notation.  See \url{https://www.mathworks.com/help/matlab/ref/toeplitz.html} and \url{https://github.com/JuliaMatrices/ToeplitzMatrices.jl}.  Note that with this interface design, if $vr_1 \neq vr_1$ there is an error.  }   As an example, to construct
\begin{align}
 vr &= \begin{bmatrix} a & f & g & h\end{bmatrix} \in \R^4\\
 vc &= \begin{bmatrix} a & b & c & d & e\end{bmatrix} \in \R^5\\
 \toep(vr,vc) &= \begin{bmatrix}
a & b & c & d & e \\
f & a & b & c & d \\
g & f & a & b & c \\
h & g & f & a & b
\end{bmatrix} \in \R^{4 \times 5}
 \end{align}

\paragraph{Banded Matrices}
Next, consider a banded matrix (\url{https://en.wikipedia.org/wiki/Band_matrix}).  This is a sparse matrix where only a ``small'' number of diagonals below and/or above the main diagonal are non-zero.  Unlike a Toeplitz matrix, the diagonals need not be constant.\footnote{In principle there could be banded Toeplitz matrices (i.e., only a certain bandwidth of off diagonals are non-zero), but at this point we are unaware of software packages along those lines.}

To denote a banded matrix, one needs to specify (1) how many lower and upper diagonals are in the matrix; and (2) the values of those diagonals.  For example, a diagonal matrix has $0$ lower and $0$ upper diagonals while a tridiagonal matrix has $1$ of each.

As an example of the notation, first define vectors of diagonals
\begin{align}
B_{-1} &\equiv \begin{bmatrix} B_{21} & B_{32} & B_{43} & B_{54} \end{bmatrix}\in\R^4\\
B_{0} &\equiv \begin{bmatrix} B_{11} & B_{22} & B_{33} & B_{44} & B_{55} \end{bmatrix}\in\R^5\\
B_{+1} &\equiv \begin{bmatrix} B_{12} & B_{23} & B_{34} & B_{45} & B_{56} \end{bmatrix}\in\R^5\\
B_{+2} &\equiv \begin{bmatrix} B_{13} & B_{24} & B_{35} & B_{46} \end{bmatrix}\in\R^4\\
\intertext{The $\band^{n,m}_{\ell,u}(\cdot)$ function is used to define a banded matrix given diagonals where the $\ell$ is number of bands below the diagonal and $u$ is the number of bands above the diagonal.  The function then takes a list of the diagonals in order (i.e. lower bands, the diagonal band, then upper bands)}
\band^{5,6}_{1,1}(B_{-1}, B_{0}, B_{+1}) &= \begin{bmatrix}
 B_{11} & B_{12} & 0      & \cdots & \cdots & 0 \\
 B_{21} & B_{22} & B_{23} & \ddots & \ddots & \vdots \\
  0     & B_{32} & B_{33} & B_{34} & \ddots & \vdots \\
 \vdots & \ddots & B_{43} & B_{44} & B_{45} & 0 \\
 \vdots & \ddots & \ddots & B_{54} & B_{55} & B_{56}
\end{bmatrix}\in \R^{5\times 6}\\
\intertext{And other with a variation on the columns with no sub-diagonals and two super-diagonals}
\band_{0,2}^{5,6}(B_{0}, B_{+1}, B_{+2}) &= \begin{bmatrix}
 B_{11} & B_{12} & B_{13} & 0      & \cdots & 0 \\
 0 & B_{22} & B_{23} & B_{24} &0 & \vdots \\
  \vdots      & 0 & B_{33} & B_{34} & B_{35} & 0 \\
 \vdots & \ddots & 0 & B_{44} & B_{45} & B_{46} \\
 \vdots & \ddots & \ddots & 0 & B_{55} & B_{56}
\end{bmatrix}\in \R^{5\times 6}
\intertext{The reason that the $(n,m)$ and $(l,u)$ are both needed is the possibility of additional zeros.  For example, simply adding another column }
\band_{0,2}^{5,7}(B_{0}, B_{+1}, B_{+2}) &= \begin{bmatrix}
 B_{11} & B_{12} & B_{13} & 0      & \cdots & 0  & 0 \\
 0 & B_{22} & B_{23} & B_{24} &0 & \vdots & \vdots \\
  \vdots      & 0 & B_{33} & B_{34} & B_{35} & 0 & 0 \\
 \vdots & \ddots & 0 & B_{44} & B_{45} & B_{46} & 0\\
 \vdots & \ddots & \ddots & 0 & B_{55} & B_{56} & 0
\end{bmatrix}\in \R^{5\times 7}
\end{align}
Note that a Topelitz matrix where many of the diagonals are $0$ can be written as a banded matrix, albeit by dropping the extra structure
\begin{align}
\band_{1,2}^{4,5}\left(f\times \mathbf{1}_3, a\times \mathbf{1}_4, b\times \mathbf{1}_4, c\times \mathbf{1}_3\right)
   &= \toep(\begin{bmatrix}a & f & 0 & 0 \end{bmatrix},\begin{bmatrix}a & b & c & 0 & 0 \end{bmatrix}) \\
   &= \begin{bmatrix}
	a & b & c & 0 & 0 \\
	f & a & b & c & 0 \\
	0 & f & a & b & c \\
	0 & 0 & f & a & b
	\end{bmatrix} \in \R^{4 \times 5}\\
\end{align}

\paragraph{Tridiagonal Matrices}
A final set of matrices are sparse, tridiagonal matrices.  This is a particular type of square banded matrix with a single off-diagonal in each direction.  As always, the extra structure leads to specialized operations.  For example,
\begin{align}
B_{-1} &\equiv \begin{bmatrix} B_{21} & B_{32} & B_{43} & B_{54} \end{bmatrix}\in\R^4\\
B_{0} &\equiv \begin{bmatrix} B_{11} & B_{22} & B_{33} & B_{44} & B_{55} \end{bmatrix}\in\R^5\\
B_{+1} &\equiv \begin{bmatrix} B_{12} & B_{23} & B_{34} & B_{45} \end{bmatrix}\in\R^4\\
\intertext{Note in the above that we redefined the $B_{+1}$ vector since otherwise the matrix would not be square.  Collecting,}
\tridiag(B_{-1}, B_0, B_{+1})&=
\begin{bmatrix}
 B_{11} & B_{12} & 0      & \cdots & 0 \\
 B_{21} & B_{22} & B_{23} & \ddots & \vdots \\
  0     & B_{32} & B_{33} & B_{34} & \vdots \\
 \vdots & \ddots & B_{43} & B_{44} & B_{45}\\
 \vdots & \ddots & \ddots & B_{54} & B_{55}
\end{bmatrix}\in \R^{5\times 5}\\
\intertext{Which is a banded square matrix}
&= \band_{1,1}^{5,5}(B_{-1}, B_{0}, B_{+1})
\end{align}
  If the diagonals and off-diagonals are all constant, then it is also a Toeplitz matrix,

\begin{align}
\tridiag\left(f\times \mathbf{1}_3, a\times \mathbf{1}_4, b\times \mathbf{1}_3\right) &= \begin{bmatrix}
	a & b & 0 & 0 \\
	f & a & b & 0 \\
	0 & f & a & b \\
	0 & 0 & f & a
	\end{bmatrix} \in \R^{4 \times 4}\\
	&= \toep(\begin{bmatrix}a & f & 0 & 0 \end{bmatrix},\begin{bmatrix}a & b & 0 & 0 \end{bmatrix})\\
	&=\band_{1,1}^{4,4}\left(f\times \mathbf{1}_3, a\times \mathbf{1}_4, b\times \mathbf{1}_3 \right)
\end{align}




\section{Boundary extrapolation under mixed boundary conditions}
Consider solving $v$ on an irregular extended grid $\overline{x} = \set{x_i}_{i=0}^{M+1}$ with the corresponding interior grid $x = \set{x_i}_{i=1}^M $ such that mixed boundary conditions \eqref{eq:mixed-BC1} and \eqref{eq:mixed-BC2} are applied. As described in Section \ref{subsec:applying-bc}, differential operators with boundary conditions $B$ applied, $L^B$, can be used to solve the system $L^B v = f$ in \eqref{eq:system-on-interior} to find $v$ on the interior grid without stacking up the boundary conditions manually. Note that the resulting interior solution $v$ does not contain the value of $v$ on the boundary, $\overline{v}_0 = v(x_0)$ and $\overline{v}_{M+1} = v(x_{M+1})$. 

To retrieve $\overline{v}_0 $ and $\overline{v}_{M+1}$ to construct $\overline{v}$ from $v$, first note that the mixed boundary conditions can be discretized as follows:
\begin{align}
&\frac{\overline{v}_1 - \overline{v}_0}{\Delta_{0,+}} + \underline{\xi} \overline{v}_0 = 0 \label{eq:mixed-discretized-lb} \\
&\frac{\overline{v}_{M+1} - \overline{v}_M}{\Delta_{M+1,-}} + \overline{\xi} \overline{v}_{M+1} = 0 \label{eq:mixed-discretized-ub}
\end{align}
as shown in \ref{subsubsec-irregular-grids-mixed-boundary-conditions}, using forward difference and backward difference scheme for the lower bound and upper bound respecitvely. Rearranging \eqref{eq:mixed-discretized-lb} and \eqref{eq:mixed-discretized-ub} gives
\begin{align}
\overline{v}_0 = \frac{1}{1-\underline{\xi} \Delta_{0,+} } \overline{v}_1 \\
\overline{v}_{M+1} = \frac{1}{1+\overline{\xi} \Delta_{M+1,-} } \overline{v}_M
\end{align}
Note that $\overline{v}_1 = v_1$ and $\overline{v}_M = v_M$ as the resulting solutions on the interior nodes are identical. Also, by the definition, we have $\Delta_{0,+} = x_1 - x_0 = \Delta_{1,-}$ and $\Delta_{M+1,-} = x_{M+1} - x_M = \Delta_{M, +}$, which yields the following boundary extrapolation scheme
\begin{align}
\overline{v}_0 = \frac{1}{1-\underline{\xi} \Delta_{1,-} } {v}_1 \\
\overline{v}_{M+1} = \frac{1}{1+\overline{\xi} \Delta_{M,+} } {v}_M
\end{align}
to construct
\begin{align}
\overline{v} &= \begin{bmatrix}
\overline{v}_0 \\
v  \\
\overline{v}_{M+1}
\end{bmatrix} \\ &=
\begin{bmatrix}
\dfrac{1}{1-\underline{\xi} \Delta_{1,-} } {v}_1 \\
v  \\
\dfrac{1}{1+\overline{\xi} \Delta_{M,+} } {v}_M
\end{bmatrix} 
\end{align}
from $v$.

\section{Derivation by substitution}
One can also derive the formula for $L_{1-}^B, L_{1+}^B, L_2^B$ in \eqref{eq:L-1-regular}, \eqref{eq:L-1-plus-regular}, \eqref{eq:L-2-regular} by substitution. For simplicity, here we focus on the case when we have regular grids, i.e., $x_{i+1} - x_i = \Delta$ for some $\Delta > 0$ for all $i = 0, ..., M$.

Using the backwards first-order difference, \eqref{eq:mixed-BC1} implies
\begin{align}
\dfrac{\tilde{v}({x_{1}}) - \tilde{v}(x_{0})}{\Delta} &= - \underline{\xi} \tilde{v}({x_{0}})
\end{align}
i.e.,
\begin{align}\label{eq:BC1-extrapolation-uniform}
\tilde{v}(x_0) = \frac{1}{1-\underline{\xi} \Delta } \tilde{v}(x_1)
\end{align}
at the lower bound.

Likewise, \eqref{eq:mixed-BC2} under the forwards first-order difference yields
\begin{align}
\dfrac{\tilde{v}(x_{M+1}) - \tilde{v}({x_{M}})}{\Delta} &= - \overline{\xi} \tilde{v}({x_{M+1} })
\end{align}
i.e.,
\begin{align}\label{eq:BC2-extrapolation-uniform}
\tilde{v}(x_{M+1}) = \frac{1}{1+\overline{\xi} \Delta } \tilde{v}(x_M)
\end{align}
at the upper bound.

The discretized central difference of second order under \eqref{eq:mixed-BC1} at the lower bound is, by substituting \eqref{eq:BC1-extrapolation-uniform} in,
\begin{align}
\dfrac{\tilde{v}({x_{1}} + \Delta) - 2 \tilde{v}({x_{1}}) + \tilde{v}(x_{\min})}{\Delta^2} &=   \dfrac{\tilde{v}({x_{1}} + \Delta) - \tilde{v}({x_{1}})}{\Delta^2} - \dfrac{1}{\Delta}\dfrac{\tilde{v}({x_{1}}) - \tilde{v}(x_{\min}) }{\Delta}  \\
&= \dfrac{\tilde{v}({x_{1}} + \Delta) - \tilde{v}({x_{1}})}{\Delta^2} + \dfrac{1}{\Delta} \underline{\xi} \tilde{v}({x_{1}})  \\
&= \dfrac{1}{\Delta^2}  (- 1 + \Delta \underline{\xi})^{-1} \tilde{v}({x_{1}})  + \dfrac{1}{\Delta^2}  \tilde{v}({x_{1}} + \Delta)
\end{align}
Similarly, by \eqref{eq:mixed-BC2}, we have
\begin{align}
\dfrac{\tilde{v}(x_{\max}) - 2 \tilde{v}({x_{M}} ) + \tilde{v}({x_{M}} -\Delta)}{\Delta^2} &=   \dfrac{\tilde{v}({x_{M}} - \Delta) - \tilde{v}({x_{M}})}{\Delta^2} + \dfrac{1}{\Delta}\dfrac{ \tilde{v}(x_{\max}) - \tilde{v}({x_{M}}) }{\Delta}  \\
&= \dfrac{\tilde{v}({x_{M}} - \Delta) - \tilde{v}({x_{M}})}{\Delta^2}  - \dfrac{1}{\Delta} \overline{\xi} \tilde{v}({x_{M}})  \\
&= \dfrac{1}{\Delta^2}  (- 1 - \Delta \overline{\xi})^{-1} \tilde{v}({x_{M}})  + \dfrac{1}{\Delta^2}  \tilde{v}({x_{M}} - \Delta)
\end{align}
at the upper bound.

Thus, the corresponding discretized differential operator $L_{1-}$, $L_{1+}$, and $L_2$ are defined as

\begin{align}
L_{1-}^B &\equiv \frac{1}{\Delta}\begin{bmatrix}
1 - (1 - \underline{\xi} \Delta)^{-1} &0&0&\dots&0&0&0\\
-1&1&0&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&-1&1&0\\
0&0&0&\cdots&0&-1&1
\end{bmatrix}_{M\times M} \\
L_{1+}^B &\equiv \frac{1}{\Delta}\begin{bmatrix}
-1&1&0&\dots&0&0&0\\
0&-1&1&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&0&-1&1\\
0&0&0&\cdots&0&0&-1+(1-\overline{\xi} \Delta)^{-1}
\end{bmatrix}_{M\times M} \\
L_2^B &\equiv \frac{1}{\Delta^2}\begin{bmatrix}
-2 - (1 - \underline{\xi}\Delta)^{-1} &1&0&\dots&0&0&0\\
1&-2&1&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&1&-2&1\\
0&0&0&\cdots&0&1&-2 + (1 + \overline{\xi}\Delta)^{-1}
\end{bmatrix}_{M\times M}
\end{align}


\iffalse
\subsection{Differential operators by basis}
Define the following basis matrices:

\begin{align}
U_1^{-} &\equiv \begin{bmatrix}
1  &0&0&\dots&0&0&0\\
-1&1&0&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&-1&1&0\\
0&0&0&\cdots&0&-1&1
\end{bmatrix}_{M\times M}\label{eq:L-1-basis} \\
U_1^{+} &\equiv \begin{bmatrix}
-1  &1&0&\dots&0&0&0\\
0&-1&1&\dots&0&0&0\\
\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
0&0&0&\dots&0&-1&1\\
0&0&0&\cdots&0&0&-1
\end{bmatrix}_{M\times M}\label{eq:L-1+-basis} \\
\end{align}

and the boundary conditions for the reflecting conditions:

\begin{align}
B_{1}  &\equiv \begin{bmatrix}
(1 + \underline{\xi} \Delta^{-1}_{1,-})^{-1} &0&\dots&0&0\\
0&0&\dots&0&0\\
\vdots&\vdots&\ddots&\vdots&\vdots\\
0&0&\cdots&0&0\\
0&0&\cdots&0&0
\end{bmatrix}_{M\times M} \\
B_{M}  &\equiv \begin{bmatrix}
0 &0&\dots&0&0\\
0&0&\dots&0&0\\
\vdots&\vdots&\ddots&\vdots&\vdots\\
0&0&\cdots&0&0\\
0&0&\cdots&0&(1 - \overline{\xi} \Delta^{-1}_{M,+})^{-1}
\end{bmatrix}_{M\times M}
\end{align}

\subsubsection{Regular grids}
For regular grids with the uniform distance of $\Delta > 0$, \eqref{eq:L-1-regular} and \eqref{eq:L-2-regular} can be represented by

\begin{align}
L_{1-} &= \dfrac{1}{\Delta} U_1^{-} - B_1 \\
L_{1+} &= \dfrac{1}{\Delta} U_1^{+} + B_{M} \\
L_2 &= \dfrac{1}{\Delta^2} (U_1^+ - U_1^-) + B_1 + B_{M}
\end{align}

\subsubsection{Irregular grids}
For notational brevity, for vectors with the same size, $x_1, x_2$, define $x_1 x_2$ as the elementwise-multiplied vector. Also, let $\Delta_-^\circ, \Delta_+^\circ$ as the vectors of differences on the interior nodes, i.e., $\Delta_{-}^\circ = \set{\Delta_{i,-}}_{i=1}^M$, $\Delta_{+}^\circ = \set{\Delta_{i,}}_{i=1}^M$. Then, we have
\begin{align}
L_{1-} &= \text{diag}(\Delta_{-}^{\circ} )^{-1} U_1^{-} - B_1 \\
L_{1+} &= \text{diag}(\Delta_{+}^{\circ} )^{-1} U_1^{+} + B_{M} \\
L_2 &= \text{diag} \left[ \frac{1}{2} ( {\Delta_{+}^{\circ}} + {\Delta_{-}^{\circ}} ) {\Delta_{+}^{\circ}} \right]^{-1}  U_1^{+} -
\text{diag} \left[ \frac{1}{2} ( {\Delta_{+}^{\circ}} + {\Delta_{-}^{\circ}} ) {\Delta_{-}^{\circ}} \right]^{-1}  U_1^{-}
+ B_1 + B_{M}
\end{align}
We can simplify this expression further by introducing a new notation. Let $x^{-1}$ be defined as the elementwise inverse of a vector $x$ that contains no zero element. Then, $L_2$ can be represented as
\begin{align}
L_2 &=
2\left[ \text{diag} \left( ( {\Delta_{+}^{\circ}} + {\Delta_{-}^{\circ}} )^{-1} {\Delta_{+}^{\circ}}^{-1} \right) U_1^{+} -
\text{diag} \left( ( {\Delta_{+}^{\circ}} + {\Delta_{-}^{\circ}} )^{-1} {\Delta_{-}^{\circ}}^{-1} \right) U_1^{-}  \right]
+ B_1 + B_{M} \\ \label{eq:L-2-by-basis}
&= 2 \text{diag} \left( ( {\Delta_{+}^{\circ}} + {\Delta_{-}^{\circ}} )^{-1} \right) \left[ \text{diag} \left(  {\Delta_{+}^{\circ}}^{-1} \right) U_1^{+} -
\text{diag} \left(  {\Delta_{-}^{\circ}}^{-1} \right) U_1^{-}  \right]
+ B_1 + B_{M}
\end{align}


The diagonal elements of \eqref{eq:L-2-by-basis} are also identical with the one provided in \eqref{eq:L-2} -- to see this, note that the diagonal elements of \eqref{eq:L-2-by-basis}, modulo $B_1$ and $B_{M}$, are
\begin{align}
-2 \left[ ({\Delta_{+}^{\circ}} + {\Delta_{-}^{\circ}})^{-1} {\Delta_{+}^{\circ}}^{-1} + ({\Delta_{+}^{\circ}} + {\Delta_{-}^{\circ}})^{-1} {\Delta_{-}^{\circ}}^{-1} \right] &= -2 ({\Delta_{+}^{\circ}} + {\Delta_{-}^{\circ}})^{-1}  ( {\Delta_{+}^{\circ}}^{-1} + {\Delta_{-}^{\circ}}^{-1} ) \\
&= -2({\Delta_{+}^{\circ}} + {\Delta_{-}^{\circ}})^{-1} ({\Delta_{+}^{\circ}}^{-1} {\Delta_{-}^{\circ}}^{-1}) ({\Delta_{+}^{\circ}} + {\Delta_{-}^{\circ}} )  \\
&= -2 ({\Delta_{+}^{\circ}}^{-1} {\Delta_{-}^{\circ}}^{-1})
\end{align}
which is identical with $\text{diag} (L_2)$ with $L_2$ from \eqref{eq:L-2} except the first row and last row that are affected by $B_1$ and $B_{M}$.

\fi


\bibliography{hact}
% The notebook is based on my previous version that can be found at https://github.com/ubcecon/computing_and_datascience/blob/a33d14191afba2d13598b331b3623a9512dccc90/continuous_time_methods/notes/discretized-differential-operator-derivation.tex by @chiyahn
\end{document}
